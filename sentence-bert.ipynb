{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install faiss-gpu\n",
    "# !pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-19 21:48:19.324699: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "import faiss\n",
    "import time\n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # 병합할 CSV 파일들이 있는 디렉토리 경로\n",
    "# directory_path = './data/format/'\n",
    "\n",
    "# # 디렉토리 내의 모든 CSV 파일을 리스트로 가져옴\n",
    "# csv_files = [file for file in os.listdir(directory_path) if file.endswith('.csv')]\n",
    "\n",
    "# # CSV 파일들을 담을 빈 DataFrame 생성\n",
    "# combined_data = pd.DataFrame()\n",
    "\n",
    "# # 각 CSV 파일을 읽어와서 combined_data에 추가\n",
    "# for file in csv_files:\n",
    "#     file_path = os.path.join(directory_path, file)\n",
    "#     df = pd.read_csv(file_path,encoding='cp949',index_col=0)\n",
    "#     combined_data = pd.concat([combined_data, df], ignore_index=True)``\n",
    "\n",
    "# # 결과를 하나의 CSV 파일로 저장\n",
    "# combined_data.to_csv('train_combined.csv',encoding='cp949', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>morpheme</th>\n",
       "      <th>bio_tag</th>\n",
       "      <th>pos</th>\n",
       "      <th>format</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>귀의 상태에 대해 문의 주셨습니다 .</td>\n",
       "      <td>XO OOO OO OO OOOOO O</td>\n",
       "      <td>B-BD O O O O O</td>\n",
       "      <td>(귀,NNG) / (의,JKG) / (상태,NNG) / (에,JKB) / (대해,V...</td>\n",
       "      <td>Word | POS | Entity | BIO \\n귀의 |귀(NNG)+의(JKG)|...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>현재 질문자분의 귀의 상태로 보아가벼운 염증성 질환을 의심할 수 있습니다 .</td>\n",
       "      <td>OO OOOOO XO OOO OOOOO OOO OOO OOO O OOOO O</td>\n",
       "      <td>O O B-BD O O O O O O O O</td>\n",
       "      <td>(현재,MAG) / (질문,NNG) / (자분,NNG) / (의,JKG) / (귀,...</td>\n",
       "      <td>Word | POS | Entity | BIO \\n현재 |현재(MAG)| False...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>심하지 않은 염증소견이므로가볍게 소독하시고 지켜보시다가분비물이 나오고 있고 통증이 ...</td>\n",
       "      <td>OOO OO OOOOOOOOOO OOOOO OOOOOOOOOO OOO OO XXO ...</td>\n",
       "      <td>O O O O O O O B-ST O O O O O O O B-ST O O O O</td>\n",
       "      <td>(심하,VA) / (지,EC) / (않,VX) / (은,ETM) / (염증,NNG)...</td>\n",
       "      <td>Word | POS | Entity | BIO \\n심하지 |심하(VA)+지(EC)|...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>답변이 도움이 되시길 바랍니다 .</td>\n",
       "      <td>OOO OOO OOO OOOO O</td>\n",
       "      <td>O O O O O</td>\n",
       "      <td>(답변,NNG) / (이,JKS) / (도움,NNG) / (이,JKS) / (되,V...</td>\n",
       "      <td>Word | POS | Entity | BIO \\n답변이 |답변(NNG)+이(JKS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>비행기 여행이 걱정되어 질문하신 것 같습니다 .</td>\n",
       "      <td>OOO OOO OOOO OOOO O OOOO O</td>\n",
       "      <td>O O O O O O O</td>\n",
       "      <td>(비행기,NNG) / (여행,NNG) / (이,JKS) / (걱정,NNG) / (되...</td>\n",
       "      <td>Word | POS | Entity | BIO \\n비행기 |비행기(NNG)| Fal...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentences  \\\n",
       "0                               귀의 상태에 대해 문의 주셨습니다 .   \n",
       "1         현재 질문자분의 귀의 상태로 보아가벼운 염증성 질환을 의심할 수 있습니다 .   \n",
       "2  심하지 않은 염증소견이므로가볍게 소독하시고 지켜보시다가분비물이 나오고 있고 통증이 ...   \n",
       "3                                 답변이 도움이 되시길 바랍니다 .   \n",
       "4                         비행기 여행이 걱정되어 질문하신 것 같습니다 .   \n",
       "\n",
       "                                            morpheme  \\\n",
       "0                               XO OOO OO OO OOOOO O   \n",
       "1         OO OOOOO XO OOO OOOOO OOO OOO OOO O OOOO O   \n",
       "2  OOO OO OOOOOOOOOO OOOOO OOOOOOOOOO OOO OO XXO ...   \n",
       "3                                 OOO OOO OOO OOOO O   \n",
       "4                         OOO OOO OOOO OOOO O OOOO O   \n",
       "\n",
       "                                         bio_tag  \\\n",
       "0                                 B-BD O O O O O   \n",
       "1                       O O B-BD O O O O O O O O   \n",
       "2  O O O O O O O B-ST O O O O O O O B-ST O O O O   \n",
       "3                                      O O O O O   \n",
       "4                                  O O O O O O O   \n",
       "\n",
       "                                                 pos  \\\n",
       "0  (귀,NNG) / (의,JKG) / (상태,NNG) / (에,JKB) / (대해,V...   \n",
       "1  (현재,MAG) / (질문,NNG) / (자분,NNG) / (의,JKG) / (귀,...   \n",
       "2  (심하,VA) / (지,EC) / (않,VX) / (은,ETM) / (염증,NNG)...   \n",
       "3  (답변,NNG) / (이,JKS) / (도움,NNG) / (이,JKS) / (되,V...   \n",
       "4  (비행기,NNG) / (여행,NNG) / (이,JKS) / (걱정,NNG) / (되...   \n",
       "\n",
       "                                              format  \n",
       "0  Word | POS | Entity | BIO \\n귀의 |귀(NNG)+의(JKG)|...  \n",
       "1  Word | POS | Entity | BIO \\n현재 |현재(MAG)| False...  \n",
       "2  Word | POS | Entity | BIO \\n심하지 |심하(VA)+지(EC)|...  \n",
       "3  Word | POS | Entity | BIO \\n답변이 |답변(NNG)+이(JKS...  \n",
       "4  Word | POS | Entity | BIO \\n비행기 |비행기(NNG)| Fal...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('./data/train_combined_no_coT.csv',index_col=0,encoding='cp949')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Word | POS | Entity | BIO ',\n",
       " '귀의 |귀(NNG)+의(JKG)| True | B-BD ',\n",
       " '상태에 |상태(NNG)+에(JKB)| False | O ',\n",
       " '대해 |대해(VV+EC)| False | O ',\n",
       " '문의 |문(NNG)+의(JKG)| False | O ',\n",
       " '주셨습니다 |주(VV)+셨(EP+EP)+습니다(EF)| False | O ',\n",
       " '. |.(SF)| False | O ']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.iloc[0]['format'].split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 데이터 수: 8758\n",
      "train 데이터 중복제거 후: 1830\n"
     ]
    }
   ],
   "source": [
    "print('train 데이터 수:', len(train))\n",
    "print('train 데이터 중복제거 후:', len(set(train['sentences'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1830\n"
     ]
    }
   ],
   "source": [
    "# 'sentences' 열을 기준으로 중복된 행을 제거\n",
    "train = train.drop_duplicates(subset='sentences')\n",
    "\n",
    "# 중복 제거 후의 train 데이터 확인\n",
    "print(len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 데이터셋을 불러온다고 가정\n",
    "# dataset = pd.read_csv('your_dataset.csv')\n",
    "\n",
    "# 데이터셋을 훈련 데이터와 테스트 데이터로 나눈다\n",
    "train_data, test_data = train_test_split(train, test_size=450, random_state=42)\n",
    "\n",
    "# 나머지 데이터는 train_data로 남아있음\n",
    "\n",
    "# train_data와 test_data를 각각 저장한다\n",
    "train_data.to_csv('./data/no_coT/train_data.csv', index=False,encoding='cp949')\n",
    "test_data.to_csv('./data/no_coT/test_data.csv', index=False,encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['대부분의 경우 특별한 치료가 필요치는 않습니다 .',\n",
       " '측두엽 간질 중에서도 측두엽 부위의 결함이나 상처가 있으면 약물조절이 어려울 수도 있습니다 .',\n",
       " '기침과 가래가 있다고 해서 천식이라고 단정 지을 수는 없으니호흡기 내과에 가셔서 흉부 사진과 폐기능 검사 등의 기초적인 검사와 진료를 받으시고정확한 진단 하에 치료를 받으시기 바랍니다 .',\n",
       " '척추관 협착증으로 질문을 주셨군요 답변 가 ) 치료 불가능합니다 .',\n",
       " '시간이 가면서 회복 될 것입니다 .',\n",
       " '두통의 빈도가 한달 5회 이상 , 두통약을 그 때마다 복용해야 하거나 효과가 없다면신경과 진료가 필요합니다 .',\n",
       " '피가 섞인 분비물이 걱정되어 질문하신 것 같습니다 .',\n",
       " '정상인의 경우 8시간 이상의 금식후 측정한 공복혈당이 100mg dL미만이고 , 식후 2시간 혈당이 140 mg dL미만입니다 .',\n",
       " '문의에 답변드리겠습니다 .',\n",
       " '허리디스크 진단을 받으셨군요 허리디스크로인해 신경의 압박이 심한 경우에는 수술이 필요합니다 .']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentence = list(train_data['sentences'])\n",
    "train_sentence[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임베딩 된 벡터 수 : 1380\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer(\"jhgan/ko-sroberta-multitask\")\n",
    "encoded_data = model.encode(train_sentence)\n",
    "print('임베딩 된 벡터 수 :', len(encoded_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "embedding_file_path = 'encoded_train_data.pkl'\n",
    "# 임베딩된 데이터를 pickle 파일로 저장\n",
    "with open('./data/pickle/'+embedding_file_path, 'wb') as f:\n",
    "    pickle.dump(encoded_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list_path = 'train_list_data.pkl'\n",
    "with open('./data/pickle/'+train_list_path, 'wb') as f:\n",
    "    pickle.dump(train_sentence, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data = pd.read_csv('./data/eval_combined.csv',encoding='cp949')\n",
    "print(\"eval 데이터 수\",len(eval_data['sentences']))\n",
    "print(\"eval 데이터 중복 제거 후\",len(set(eval_data['sentences'])))\n",
    "queries = list(set(eval_data['sentences']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k = 5\n",
    "all_matched = []\n",
    "for query in test_data.iloc[:2]['sentences']:\n",
    " query_embedding = model.encode(query, convert_to_tensor=True)\n",
    " cos_scores = util.pytorch_cos_sim(query_embedding, encoded_data)[0]\n",
    " cos_scores = cos_scores.cpu()\n",
    "\n",
    " #We use np.argpartition, to only partially sort the top_k results\n",
    " top_results = np.argpartition(-cos_scores, range(top_k))[0:top_k]\n",
    "\n",
    " print(\"\\n\\n======================\\n\\n\")\n",
    " print(\"Query:\", query)\n",
    " print(\"\\nTop 5 most similar sentences in corpus:\")\n",
    "\n",
    " for idx in top_results[0:top_k]:\n",
    "  print(train_sentence[idx].strip(), \"(Score: %.4f)\" % (cos_scores[idx]))\n",
    "  train_loc = train.loc[train['sentences'] == train_sentence[idx]].head(1)\n",
    "  train_loc\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16 ('sy')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c8912a2ac60011df5c7929c5b17fec914cfb6aaebbe86976a2caeafe12776e03"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
