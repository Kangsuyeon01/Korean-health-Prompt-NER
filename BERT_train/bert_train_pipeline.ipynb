{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SMVCwPlYfhOE"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-08-22 23:11:11.515934: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "/home/suyeon/.conda/envs/sy/lib/python3.9/site-packages/transformers/generation_utils.py:24: FutureWarning: Importing `GenerationMixin` from `src/transformers/generation_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import GenerationMixin` instead.\n",
            "  warnings.warn(\n",
            "/home/suyeon/.conda/envs/sy/lib/python3.9/site-packages/transformers/generation_tf_utils.py:24: FutureWarning: Importing `TFGenerationMixin` from `src/transformers/generation_tf_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import TFGenerationMixin` instead.\n",
            "  warnings.warn(\n",
            "You are using torch==1.7.1+cu110, but torch>=1.9.0 is required to use MCTCTModel. Please upgrade torch.\n",
            "You are using torch==1.7.1+cu110, but torch>=1.10.0 is required to use ViltModel. Please upgrade torch.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from seqeval.metrics import precision_score, recall_score, f1_score, classification_report\n",
        "import tensorflow as tf\n",
        "from transformers import BertTokenizer\n",
        "from transformers import *\n",
        "import re\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oi7lX9GXdNzw"
      },
      "source": [
        "# 1. 데이터 로드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6Smvwl7v5cLg"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"./Data/train_data.csv\",encoding='cp949')\n",
        "# 데이터 나누기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# k = 5\n",
        "# shot_sentence = df[[f'{i+1}-Shot Sentence' for i in range(k)]]\n",
        "# shot_bio = df[[f'{i+1}-Shot BIO' for i in range(k)]]\n",
        "\n",
        "# stacked_df_sentence = shot_sentence.stack().reset_index(drop=True).to_frame('sentences')\n",
        "# stacked_df_bio = shot_bio.stack().reset_index(drop=True).to_frame('bio_tag')\n",
        "\n",
        "# final_df = pd.concat([stacked_df_sentence, stacked_df_bio], axis=1)\n",
        "# final_df = final_df.drop_duplicates(subset=['sentences','bio_tag'])\n",
        "# final_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_ner_df, test_ner_df = train_test_split(df, test_size=450, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentences</th>\n",
              "      <th>morpheme</th>\n",
              "      <th>bio_tag</th>\n",
              "      <th>pos</th>\n",
              "      <th>format</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>712</th>\n",
              "      <td>먼저 성대검사와 음성검사 등을 정밀하게 하시면 원인을 아실 수 있을 겁니다 .</td>\n",
              "      <td>OO XXOOO OOOO OO OOOO OOO OOO OO O OO OOO O</td>\n",
              "      <td>O B-BD O O O O O O O O O O</td>\n",
              "      <td>(먼저,MAG) / (성대,NNG) / (검사,NNG) / (와,JC) / (음성,...</td>\n",
              "      <td>Word | POS | Entity | BIO | Thought \\n먼저 |먼저(M...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>701</th>\n",
              "      <td>퇴행성 허리 디스크 진단을 받으셨군요 퇴행성만 진행된 경우에는 수술적인 치료를 하지...</td>\n",
              "      <td>XXX XX XXX OOO OOOOO OOOO OOO OOOO OOOO OOO OO...</td>\n",
              "      <td>B-DS I-DS I-DS O O O O O O O O O O</td>\n",
              "      <td>(퇴행,NNG) / (성,XSN) / (허리,NNG) / (디스크,NNG) / (진...</td>\n",
              "      <td>Word | POS | Entity | BIO | Thought \\n퇴행성 |퇴행(...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1144</th>\n",
              "      <td>특히 축구와 같은 운동 후 호흡곤란이 심해진다면 더욱 운동 유발성 천식의 가능성이 ...</td>\n",
              "      <td>OO OOO OO OO O XXXXO OOOOO OO XX XXX XXO OOOO ...</td>\n",
              "      <td>O O O O O B-ST O O B-DS I-DS I-DS O O O</td>\n",
              "      <td>(특히,MAG) / (축구,NNG) / (와,JKB) / (같,VA) / (은,ET...</td>\n",
              "      <td>Word | POS | Entity | BIO | Thought \\n특히 |특히(M...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1201</th>\n",
              "      <td>통증이 어쩌다 한번 느껴진 경우라면 , 별 문제 없을 수 있지만 , 반복되거나 지속...</td>\n",
              "      <td>XXO OOO OO OOO OOOO O O OO OO O OOO O OOOOO OO...</td>\n",
              "      <td>B-ST O O O O O O O O O O O O O O O O O O</td>\n",
              "      <td>(통증,NNG) / (이,JKS) / (어쩌다,MAJ) / (한,MM) / (번,N...</td>\n",
              "      <td>Word | POS | Entity | BIO | Thought \\n통증이 |통증(...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>332</th>\n",
              "      <td>체온상승 등으로 유발된 자율신경계의 이상반응에 의해 미주신경인 부교감신경의 과도한 ...</td>\n",
              "      <td>XXXX OOO OOO OOOOOO OOOOO OO XXXXO XXXXXO OOO ...</td>\n",
              "      <td>B-ST O O O O O B-BD B-BD O O B-ST B-ST B-DS O ...</td>\n",
              "      <td>(체온,NNG) / (상승,NNG) / (등,NNB) / (으로,JKB) / (유발...</td>\n",
              "      <td>Word | POS | Entity | BIO | Thought \\n체온상승 |체온...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              sentences  \\\n",
              "712         먼저 성대검사와 음성검사 등을 정밀하게 하시면 원인을 아실 수 있을 겁니다 .   \n",
              "701   퇴행성 허리 디스크 진단을 받으셨군요 퇴행성만 진행된 경우에는 수술적인 치료를 하지...   \n",
              "1144  특히 축구와 같은 운동 후 호흡곤란이 심해진다면 더욱 운동 유발성 천식의 가능성이 ...   \n",
              "1201  통증이 어쩌다 한번 느껴진 경우라면 , 별 문제 없을 수 있지만 , 반복되거나 지속...   \n",
              "332   체온상승 등으로 유발된 자율신경계의 이상반응에 의해 미주신경인 부교감신경의 과도한 ...   \n",
              "\n",
              "                                               morpheme  \\\n",
              "712         OO XXOOO OOOO OO OOOO OOO OOO OO O OO OOO O   \n",
              "701   XXX XX XXX OOO OOOOO OOOO OOO OOOO OOOO OOO OO...   \n",
              "1144  OO OOO OO OO O XXXXO OOOOO OO XX XXX XXO OOOO ...   \n",
              "1201  XXO OOO OO OOO OOOO O O OO OO O OOO O OOOOO OO...   \n",
              "332   XXXX OOO OOO OOOOOO OOOOO OO XXXXO XXXXXO OOO ...   \n",
              "\n",
              "                                                bio_tag  \\\n",
              "712                          O B-BD O O O O O O O O O O   \n",
              "701                  B-DS I-DS I-DS O O O O O O O O O O   \n",
              "1144            O O O O O B-ST O O B-DS I-DS I-DS O O O   \n",
              "1201           B-ST O O O O O O O O O O O O O O O O O O   \n",
              "332   B-ST O O O O O B-BD B-BD O O B-ST B-ST B-DS O ...   \n",
              "\n",
              "                                                    pos  \\\n",
              "712   (먼저,MAG) / (성대,NNG) / (검사,NNG) / (와,JC) / (음성,...   \n",
              "701   (퇴행,NNG) / (성,XSN) / (허리,NNG) / (디스크,NNG) / (진...   \n",
              "1144  (특히,MAG) / (축구,NNG) / (와,JKB) / (같,VA) / (은,ET...   \n",
              "1201  (통증,NNG) / (이,JKS) / (어쩌다,MAJ) / (한,MM) / (번,N...   \n",
              "332   (체온,NNG) / (상승,NNG) / (등,NNB) / (으로,JKB) / (유발...   \n",
              "\n",
              "                                                 format  \n",
              "712   Word | POS | Entity | BIO | Thought \\n먼저 |먼저(M...  \n",
              "701   Word | POS | Entity | BIO | Thought \\n퇴행성 |퇴행(...  \n",
              "1144  Word | POS | Entity | BIO | Thought \\n특히 |특히(M...  \n",
              "1201  Word | POS | Entity | BIO | Thought \\n통증이 |통증(...  \n",
              "332   Word | POS | Entity | BIO | Thought \\n체온상승 |체온...  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_ner_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ZnjvePcWflEk",
        "outputId": "b7cf92ee-f727-4bb6-e547-1c6774e0184f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentences</th>\n",
              "      <th>morpheme</th>\n",
              "      <th>bio_tag</th>\n",
              "      <th>pos</th>\n",
              "      <th>format</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>377</th>\n",
              "      <td>그래도 호전 없으면 허리 아픈지 점검 받아 보시기 바랍니다 .</td>\n",
              "      <td>OOO OO OOO XX OOO OO OO OOO OOOO O</td>\n",
              "      <td>O O O B-BD O O O O O O</td>\n",
              "      <td>(그래도,MAJ) / (호전,NNG) / (없,VA) / (으면,EC) / (허리,...</td>\n",
              "      <td>Word | POS | Entity | BIO | Thought \\n그래도 |그래도...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>548</th>\n",
              "      <td>허리 자체의 문제도 있겠지만 , 그 보다도 오히려 통증 전달 체계의 이상 여부도 확...</td>\n",
              "      <td>XX OOO OOO OOOO O O OOO OOO XX OO OOO OO OOO O...</td>\n",
              "      <td>B-BD O O O O O O O B-ST O O O O O O O</td>\n",
              "      <td>(허리,NNG) / (자체,NNG) / (의,JKG) / (문제,NNG) / (도,...</td>\n",
              "      <td>Word | POS | Entity | BIO | Thought \\n허리 |허리(N...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>979</th>\n",
              "      <td>이비인후과에서 진찰과 내시경 등으로 확인하여 제거할 수있으며 , 때로는 반복적인 검...</td>\n",
              "      <td>OOOOOOO OOO OOO OOO OOOO OOO OOOO O OOO OOOO O...</td>\n",
              "      <td>O O O O O O O O O O O O O O O O O O O O O O</td>\n",
              "      <td>(이비인후과,NNG) / (에서,JKB) / (진찰,NNG) / (과,JC) / (...</td>\n",
              "      <td>Word | POS | Entity | BIO | Thought \\n이비인후과에서 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1149</th>\n",
              "      <td>질문자 님의 경우 , 목을 움직일 경우 통증이 더 유발 된다고 하면 , 목 척추 관...</td>\n",
              "      <td>OOO OO OO O OO OOO OO XXO O OO OOO OO O X XX O...</td>\n",
              "      <td>O O O O O O O B-ST O O O O O B-BD B-BD O O O O...</td>\n",
              "      <td>(질,NNG) / (문자,NNG) / (님,XSN) / (의,JKG) / (경우,N...</td>\n",
              "      <td>Word | POS | Entity | BIO | Thought \\n질문자 |질(N...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>481</th>\n",
              "      <td>단순한 천식으로 의식을 잃는 경우는 없으나수술 후에 천식 발작이 오고 호흡부전이 왔...</td>\n",
              "      <td>OOO XXOO OOO OO OOO OOOOO OO XX XXO OO XXXXO O...</td>\n",
              "      <td>O B-DS O O O O O B-DS B-DS O B-ST O O O O O O O</td>\n",
              "      <td>(단순,NNG) / (한,XSA+ETM) / (천식,NNG) / (으로,JKB) /...</td>\n",
              "      <td>Word | POS | Entity | BIO | Thought \\n단순한 |단순(...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              sentences  \\\n",
              "377                  그래도 호전 없으면 허리 아픈지 점검 받아 보시기 바랍니다 .   \n",
              "548   허리 자체의 문제도 있겠지만 , 그 보다도 오히려 통증 전달 체계의 이상 여부도 확...   \n",
              "979   이비인후과에서 진찰과 내시경 등으로 확인하여 제거할 수있으며 , 때로는 반복적인 검...   \n",
              "1149  질문자 님의 경우 , 목을 움직일 경우 통증이 더 유발 된다고 하면 , 목 척추 관...   \n",
              "481   단순한 천식으로 의식을 잃는 경우는 없으나수술 후에 천식 발작이 오고 호흡부전이 왔...   \n",
              "\n",
              "                                               morpheme  \\\n",
              "377                  OOO OO OOO XX OOO OO OO OOO OOOO O   \n",
              "548   XX OOO OOO OOOO O O OOO OOO XX OO OOO OO OOO O...   \n",
              "979   OOOOOOO OOO OOO OOO OOOO OOO OOOO O OOO OOOO O...   \n",
              "1149  OOO OO OO O OO OOO OO XXO O OO OOO OO O X XX O...   \n",
              "481   OOO XXOO OOO OO OOO OOOOO OO XX XXO OO XXXXO O...   \n",
              "\n",
              "                                                bio_tag  \\\n",
              "377                              O O O B-BD O O O O O O   \n",
              "548               B-BD O O O O O O O B-ST O O O O O O O   \n",
              "979         O O O O O O O O O O O O O O O O O O O O O O   \n",
              "1149  O O O O O O O B-ST O O O O O B-BD B-BD O O O O...   \n",
              "481     O B-DS O O O O O B-DS B-DS O B-ST O O O O O O O   \n",
              "\n",
              "                                                    pos  \\\n",
              "377   (그래도,MAJ) / (호전,NNG) / (없,VA) / (으면,EC) / (허리,...   \n",
              "548   (허리,NNG) / (자체,NNG) / (의,JKG) / (문제,NNG) / (도,...   \n",
              "979   (이비인후과,NNG) / (에서,JKB) / (진찰,NNG) / (과,JC) / (...   \n",
              "1149  (질,NNG) / (문자,NNG) / (님,XSN) / (의,JKG) / (경우,N...   \n",
              "481   (단순,NNG) / (한,XSA+ETM) / (천식,NNG) / (으로,JKB) /...   \n",
              "\n",
              "                                                 format  \n",
              "377   Word | POS | Entity | BIO | Thought \\n그래도 |그래도...  \n",
              "548   Word | POS | Entity | BIO | Thought \\n허리 |허리(N...  \n",
              "979   Word | POS | Entity | BIO | Thought \\n이비인후과에서 ...  \n",
              "1149  Word | POS | Entity | BIO | Thought \\n질문자 |질(N...  \n",
              "481   Word | POS | Entity | BIO | Thought \\n단순한 |단순(...  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_ner_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0_wxnCMcLTs"
      },
      "source": [
        "훈련 데이터와 테스트 데이터의 샘플 개수를 확인해봅시다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xvqqoDy6P5Z",
        "outputId": "90744f1c-662b-470d-c9d0-9a1cf4ff9d4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "학습 데이터 샘플 개수 : 930\n",
            "테스트 데이터 샘플 개수 : 450\n"
          ]
        }
      ],
      "source": [
        "print(\"학습 데이터 샘플 개수 :\", len(train_ner_df))\n",
        "print(\"테스트 데이터 샘플 개수 :\", len(test_ner_df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "cNnzWBfKfoTT"
      },
      "outputs": [],
      "source": [
        "train_data_sentence = [sent.split() for sent in train_ner_df['sentences'].values]\n",
        "test_data_sentence = [sent.split() for sent in test_ner_df['sentences'].values]\n",
        "train_data_label = [tag.split() for tag in train_ner_df['bio_tag'].values]\n",
        "test_data_label = [tag.split() for tag in test_ner_df['bio_tag'].values]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "QDrd3nPMqIAa"
      },
      "outputs": [],
      "source": [
        "tag_to_index = {'B-DS': 0, 'I-DS': 1, 'B-ST': 2, 'I-ST': 3, 'B-BD': 4, 'I-BD': 5, 'O': 6}\n",
        "index_to_tag = {idx: tag for tag, idx in tag_to_index.items()}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7I4QROdtDKG",
        "outputId": "0a7dde4a-961c-493e-9e25-ac35f66909c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "개체명 태깅 정보의 개수 : 7\n"
          ]
        }
      ],
      "source": [
        "tag_size = len(tag_to_index)\n",
        "print('개체명 태깅 정보의 개수 :',tag_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olKkJHxbdLIK"
      },
      "source": [
        "# 2. 전처리 예시"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "87b7a6fbc7604ead99c659ce5aed4fae",
            "c760d63796f248f6892f05c141be9717",
            "cb77c882ad5a46ce96ef556c41132710",
            "40caa10bf7bd458cbf881aacde892c7f",
            "35442ebd192d4d779feb15c98ad168bc",
            "6cbe1c616d714cf1b1c3efa2de2a7f32",
            "51cc4aca4edb488a9817a0796e6e4f77",
            "6d18b1dd6f364f3d9aead1c5e2c9e865",
            "6d4cf6a2aecb44be8abd2a4bebae215f",
            "60cfc3a79a854a64a1daac329af94011",
            "1881c272a0e745c4bb2d83f49c2bf2ed",
            "061869c46a1c48108f4491dac486f4a1",
            "297c73cff2b44fbd879ee6a88248e0bb",
            "3db8cefdbe934c9a94f169b67841474c",
            "2830ac03d9e94371867426361e071deb",
            "0a1834c29de34a738729166b32b3a49c",
            "16029875a7794882934f144f2c5e83d8",
            "05e9e8f85db540ff85f52aea19b9b2b4",
            "c367d6638f874ef99e839542e41f92e2",
            "6d3ff09d980f42c18622421ef7e1b28d",
            "44d21b5cbf5446808dad177bbaeb154a",
            "3a403653781d4d24b2aaeb7f0ce8e783",
            "479d63d134b5483baca4c1e788841c82",
            "34f100f51efe4e30bb70a53db59e2d80",
            "af3708e166ad41a5b5a319d42a43d6f4",
            "2b86553056d641de8451e14acbf18e8d",
            "094ac3c76547450a9920221509b0fc2c",
            "2d920f8649e14db081002a171528f5d8",
            "81b2acbbb3a74a4da72bf683356c9516",
            "905f7c6c486e4c5d94a55e74f16ebf2f",
            "687cb1161a6c4ac395837b89fb65fdee",
            "f3857681b6b342e68c9f46e4fd087db3",
            "150906ccddba473099c62156945f0f84",
            "8fb1d9ee86984f1fb4d55df84855000f",
            "83d77ecbada443b8acbef2aa58dfa9a2",
            "487dc744300a4a1298f75743774f6345",
            "82f523cf687e47a09b60b40799b89ebc",
            "6818e90fd30242d495541a6cfd409b39",
            "4072b7b90b2f4ff3a2ae38b0592a0e08",
            "e50ec514f4cb4b7bb76ff8970a95bf02",
            "f8bbf740987640819dcd1581ac636c50",
            "a58ad45da34c465abc195c48a4540f84",
            "a9019760876948cdaa041cf9992bf836",
            "a0952ae8def047f6b91c255b21f7d641",
            "6898886cbbd2409ebda14ed60b2ab66a",
            "fdf338e909014103bc05075e4475d7b6",
            "ea660b90857b4a868856fa0007301d37",
            "2a6b8bc7fa7140d4a6b50b3754fe0041",
            "fb942159ac5b4d4c860fa2d1dc52cbb7",
            "9fb14288f90f4f729ece674c4f37a736",
            "c259d5b958bd4e19a5aa225d9bb1f057",
            "d514948d07554566925f8d36ac3ffbd4",
            "574e313faa2049a38236b0eb33a75b8c",
            "9d76271c920c4fac8934091ee4215dde",
            "1fedcaac82d14bd29a78b30839cb9d3f"
          ]
        },
        "id": "KcpPaUcSn_LT",
        "outputId": "5ce08b93-e8df-43aa-9414-ac9d4cdca057"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading file vocab.txt from cache at /home/suyeon/.cache/huggingface/hub/models--bert-base-uncased/snapshots/1dbc166cf8765166998eff31ade2eb64c8a40076/vocab.txt\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at None\n",
            "loading file tokenizer_config.json from cache at /home/suyeon/.cache/huggingface/hub/models--bert-base-uncased/snapshots/1dbc166cf8765166998eff31ade2eb64c8a40076/tokenizer_config.json\n",
            "loading configuration file config.json from cache at /home/suyeon/.cache/huggingface/hub/models--bert-base-uncased/snapshots/1dbc166cf8765166998eff31ade2eb64c8a40076/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcc3SBlfEZtS"
      },
      "source": [
        "# 3. 전처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Sxo1pIHrepW8"
      },
      "outputs": [],
      "source": [
        "def convert_examples_to_features(examples, labels, max_seq_len, tokenizer,\n",
        "                                 pad_token_id_for_segment=0, pad_token_id_for_label=-100):\n",
        "    cls_token = tokenizer.cls_token\n",
        "    sep_token = tokenizer.sep_token\n",
        "    pad_token_id = tokenizer.pad_token_id\n",
        "\n",
        "    input_ids, attention_masks, token_type_ids, data_labels = [], [], [], []\n",
        "\n",
        "    for example, label in tqdm(zip(examples, labels), total=len(examples)):\n",
        "        tokens = []\n",
        "        labels_ids = []\n",
        "        for one_word, label_token in zip(example, label):\n",
        "            subword_tokens = tokenizer.tokenize(one_word)\n",
        "            tokens.extend(subword_tokens)\n",
        "            labels_ids.extend([tag_to_index[label_token]]+ [pad_token_id_for_label] * (len(subword_tokens) - 1))\n",
        "\n",
        "        special_tokens_count = 2\n",
        "        if len(tokens) > max_seq_len - special_tokens_count:\n",
        "            tokens = tokens[:(max_seq_len - special_tokens_count)]\n",
        "            labels_ids = labels_ids[:(max_seq_len - special_tokens_count)]\n",
        "\n",
        "        tokens += [sep_token]\n",
        "        labels_ids += [pad_token_id_for_label]\n",
        "        tokens = [cls_token] + tokens\n",
        "        labels_ids = [pad_token_id_for_label] + labels_ids\n",
        "\n",
        "        input_id = tokenizer.convert_tokens_to_ids(tokens)\n",
        "        attention_mask = [1] * len(input_id)\n",
        "        padding_count = max_seq_len - len(input_id)\n",
        "\n",
        "        input_id = input_id + ([pad_token_id] * padding_count)\n",
        "        attention_mask = attention_mask + ([0] * padding_count)\n",
        "        token_type_id = [pad_token_id_for_segment] * max_seq_len\n",
        "        label = labels_ids + ([pad_token_id_for_label] * padding_count)\n",
        "\n",
        "        assert len(input_id) == max_seq_len, \"Error with input length {} vs {}\".format(len(input_id), max_seq_len)\n",
        "        assert len(attention_mask) == max_seq_len, \"Error with attention mask length {} vs {}\".format(len(attention_mask), max_seq_len)\n",
        "        assert len(token_type_id) == max_seq_len, \"Error with token type length {} vs {}\".format(len(token_type_id), max_seq_len)\n",
        "        assert len(label) == max_seq_len, \"Error with labels length {} vs {}\".format(len(label), max_seq_len)\n",
        "\n",
        "        input_ids.append(input_id)\n",
        "        attention_masks.append(attention_mask)\n",
        "        token_type_ids.append(token_type_id)\n",
        "        data_labels.append(label)\n",
        "\n",
        "    input_ids = np.array(input_ids, dtype=int)\n",
        "    attention_masks = np.array(attention_masks, dtype=int)\n",
        "    token_type_ids = np.array(token_type_ids, dtype=int)\n",
        "    data_labels = np.asarray(data_labels, dtype=np.int32)\n",
        "\n",
        "    return (input_ids, attention_masks, token_type_ids), data_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whD6ej7go8BE",
        "outputId": "bb1804a2-c31a-4eea-b2ea-2008777c5c61"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 930/930 [00:00<00:00, 1260.34it/s]\n"
          ]
        }
      ],
      "source": [
        "X_train, y_train = convert_examples_to_features(train_data_sentence, train_data_label, max_seq_len=128, tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnb6SS3UflDG",
        "outputId": "5a439e7d-6248-4115-accc-1a8ce774baaf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/450 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 450/450 [00:00<00:00, 1400.71it/s]\n"
          ]
        }
      ],
      "source": [
        "X_test, y_test = convert_examples_to_features(test_data_sentence, test_data_label, max_seq_len=128, tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEBzRbTBEc64"
      },
      "source": [
        "# 4. 모델링과 학습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "mGJyITSGfb7u"
      },
      "outputs": [],
      "source": [
        "from transformers import TFBertForTokenClassification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGbEZ4rb8YBf",
        "outputId": "030c8309-6ed3-4da8-96ae-a7bb60cfe846"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-08-22 23:11:27.581061: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
            "2023-08-22 23:11:27.581940: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
            "pciBusID: 0000:19:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6\n",
            "coreClock: 1.725GHz coreCount: 82 deviceMemorySize: 23.69GiB deviceMemoryBandwidth: 871.81GiB/s\n",
            "2023-08-22 23:11:27.582505: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 1 with properties: \n",
            "pciBusID: 0000:1a:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6\n",
            "coreClock: 1.725GHz coreCount: 82 deviceMemorySize: 23.69GiB deviceMemoryBandwidth: 871.81GiB/s\n",
            "2023-08-22 23:11:27.583024: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 2 with properties: \n",
            "pciBusID: 0000:67:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6\n",
            "coreClock: 1.725GHz coreCount: 82 deviceMemorySize: 23.69GiB deviceMemoryBandwidth: 871.81GiB/s\n",
            "2023-08-22 23:11:27.583515: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 3 with properties: \n",
            "pciBusID: 0000:68:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6\n",
            "coreClock: 1.725GHz coreCount: 82 deviceMemorySize: 23.69GiB deviceMemoryBandwidth: 871.81GiB/s\n",
            "2023-08-22 23:11:27.583571: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "2023-08-22 23:11:27.588493: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
            "2023-08-22 23:11:27.588697: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
            "2023-08-22 23:11:27.590243: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
            "2023-08-22 23:11:27.590816: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
            "2023-08-22 23:11:27.592268: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
            "2023-08-22 23:11:27.593736: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
            "2023-08-22 23:11:27.594101: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
            "2023-08-22 23:11:27.596889: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0, 1, 2, 3\n",
            "2023-08-22 23:11:27.598110: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-08-22 23:11:27.599961: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
            "pciBusID: 0000:19:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6\n",
            "coreClock: 1.725GHz coreCount: 82 deviceMemorySize: 23.69GiB deviceMemoryBandwidth: 871.81GiB/s\n",
            "2023-08-22 23:11:27.600573: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
            "2023-08-22 23:11:27.600628: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "2023-08-22 23:11:27.963020: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2023-08-22 23:11:27.963053: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
            "2023-08-22 23:11:27.963058: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
            "2023-08-22 23:11:27.963736: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 22303 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:19:00.0, compute capability: 8.6)\n"
          ]
        }
      ],
      "source": [
        "# GPU 디바이스 설정\n",
        "devices = tf.config.list_physical_devices('GPU')\n",
        "tf.config.set_visible_devices(devices[0], 'GPU')\n",
        "\n",
        "# 분산 전략 설정\n",
        "strategy = tf.distribute.OneDeviceStrategy('GPU')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0AHzTPP8Zf_",
        "outputId": "b4093572-c3d4-45fd-d2b6-33e8248a13bd"
      },
      "outputs": [],
      "source": [
        "def compute_loss(labels, logits):\n",
        "\n",
        "  loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "            from_logits=True, reduction=tf.keras.losses.Reduction.NONE)\n",
        "  active_loss = tf.reshape(labels, (-1,)) != -100\n",
        "  reduced_logits = tf.boolean_mask(tf.reshape(logits, (-1, shape_list(logits)[2])), active_loss)\n",
        "  labels = tf.boolean_mask(tf.reshape(labels, (-1,)), active_loss)\n",
        "\n",
        "  return loss_fn(labels, reduced_logits)\n",
        "\n",
        "class TFBertForTokenClassification(tf.keras.Model):\n",
        "    def __init__(self, model_name, num_labels):\n",
        "        super(TFBertForTokenClassification, self).__init__()\n",
        "        self.bert = TFBertModel.from_pretrained(model_name, from_pt=True)\n",
        "        self.classifier = tf.keras.layers.Dense(num_labels,\n",
        "                                                kernel_initializer=tf.keras.initializers.TruncatedNormal(0.02),\n",
        "                                                name='classifier')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        input_ids, attention_mask, token_type_ids = inputs\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "        all_output = outputs[0]\n",
        "        prediction = self.classifier(all_output)\n",
        "\n",
        "        return prediction\n",
        "\n",
        "def modeling(model_name, tag_size):\n",
        "    model = TFBertForTokenClassification(model_name, tag_size)\n",
        "    optimizer = tf.keras.optimizers.RMSprop(learning_rate=5e-5)\n",
        "    # multi-gpu 사용\n",
        "  \n",
        "    model.compile(optimizer=optimizer, loss=compute_loss)\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "YrElV6uL_dah"
      },
      "outputs": [],
      "source": [
        "\n",
        "class F1score(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, X_test, y_test):\n",
        "        self.X_test = X_test\n",
        "        self.y_test = y_test\n",
        "\n",
        "    def sequences_to_tags(self, label_ids, pred_ids):\n",
        "      label_list = []\n",
        "      pred_list = []\n",
        "\n",
        "      for i in range(0, len(label_ids)):\n",
        "        label_tag = []\n",
        "        pred_tag = []\n",
        "\n",
        "        for label_index, pred_index in zip(label_ids[i], pred_ids[i]):\n",
        "          if label_index != -100:\n",
        "            label_tag.append(index_to_tag[label_index])\n",
        "            pred_tag.append(index_to_tag[pred_index])\n",
        "        \n",
        "        label_list.append(label_tag)\n",
        "        pred_list.append(pred_tag)\n",
        "\n",
        "      return label_list, pred_list\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "\n",
        "      y_predicted = self.model.predict(self.X_test)\n",
        "      y_predicted = np.argmax(y_predicted, axis = 2)\n",
        "\n",
        "      label_list, pred_list = self.sequences_to_tags(self.y_test, y_predicted)\n",
        "\n",
        "      score = f1_score(label_list, pred_list)\n",
        "      print(' - f1: {:04.2f}'.format(score * 100))\n",
        "      print(classification_report(label_list, pred_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "G72kvx5RBDJS"
      },
      "outputs": [],
      "source": [
        "f1_score_report = F1score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uS__NIRH8cyI",
        "outputId": "c954b118-18ea-4b42-fea4-1bd7173078f7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file config.json from cache at /home/suyeon/.cache/huggingface/hub/models--bert-base-uncased/snapshots/1dbc166cf8765166998eff31ade2eb64c8a40076/config.json\n",
            "Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /home/suyeon/.cache/huggingface/hub/models--bert-base-uncased/snapshots/1dbc166cf8765166998eff31ade2eb64c8a40076/pytorch_model.bin\n",
            "Loading PyTorch weights from /home/suyeon/.cache/huggingface/hub/models--bert-base-uncased/snapshots/1dbc166cf8765166998eff31ade2eb64c8a40076/pytorch_model.bin\n",
            "PyTorch checkpoint contains 133,547,324 parameters\n",
            "2023-08-22 23:11:32.102401: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
            "2023-08-22 23:11:32.573104: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
            "2023-08-22 23:11:32.573169: I tensorflow/stream_executor/cuda/cuda_blas.cc:1838] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
            "Loaded 109,482,240 parameters in the TF 2.0 model.\n",
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
            "2023-08-22 23:11:32.920445: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_4449\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n",
            "2023-08-22 23:11:32.924887: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
            "2023-08-22 23:11:32.943147: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 3699850000 Hz\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function input_processing at 0x7ff0f7ed7550> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: '<' not supported between instances of 'Literal' and 'str'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function input_processing at 0x7ff0f7ed7550> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: '<' not supported between instances of 'Literal' and 'str'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:From /home/suyeon/.conda/envs/sy/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py:5043: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
            "117/117 [==============================] - 23s 89ms/step - loss: 0.5058\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-08-22 23:11:56.381897: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_27697\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " - f1: 0.30\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          BD       0.25      0.00      0.01       219\n",
            "          DS       0.00      0.00      0.00       183\n",
            "          ST       0.00      0.00      0.00       261\n",
            "\n",
            "   micro avg       0.25      0.00      0.00       663\n",
            "   macro avg       0.08      0.00      0.00       663\n",
            "weighted avg       0.08      0.00      0.00       663\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/suyeon/.conda/envs/sy/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "with strategy.scope():\n",
        "\n",
        "  model = modeling(model_name='bert-base-uncased',\n",
        "                                    tag_size = len(tag_to_index))\n",
        "  f1_score_report = F1score(X_test, y_test)\n",
        "\n",
        "model.fit(\n",
        "    X_train, y_train, epochs=1, batch_size=8,\n",
        "    callbacks = [f1_score_report]\n",
        "    )   \n",
        "\n",
        "# model.save_weights('./save_weight/{k}-shot_model')\n",
        "model.save_weights('./save_weight/bert_multi_model_1')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46u5tNFuEfVB"
      },
      "source": [
        "# 5. 예측"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Ic-E-9YC0jQ3"
      },
      "outputs": [],
      "source": [
        "def convert_examples_to_features_for_prediction(examples, max_seq_len, tokenizer,\n",
        "                                 pad_token_id_for_segment=0, pad_token_id_for_label=-100):\n",
        "    cls_token = tokenizer.cls_token\n",
        "    sep_token = tokenizer.sep_token\n",
        "    pad_token_id = tokenizer.pad_token_id\n",
        "\n",
        "    input_ids, attention_masks, token_type_ids, label_masks = [], [], [], []\n",
        "\n",
        "    for example in tqdm(examples):\n",
        "        tokens = []\n",
        "        label_mask = []\n",
        "        for one_word in example:\n",
        "            subword_tokens = tokenizer.tokenize(one_word)\n",
        "            tokens.extend(subword_tokens)\n",
        "            label_mask.extend([0]+ [pad_token_id_for_label] * (len(subword_tokens) - 1))\n",
        "\n",
        "        special_tokens_count = 2\n",
        "        if len(tokens) > max_seq_len - special_tokens_count:\n",
        "            tokens = tokens[:(max_seq_len - special_tokens_count)]\n",
        "            label_mask = label_mask[:(max_seq_len - special_tokens_count)]\n",
        "\n",
        "        tokens += [sep_token]\n",
        "        label_mask += [pad_token_id_for_label]\n",
        "        tokens = [cls_token] + tokens\n",
        "        label_mask = [pad_token_id_for_label] + label_mask\n",
        "        input_id = tokenizer.convert_tokens_to_ids(tokens)\n",
        "        attention_mask = [1] * len(input_id)\n",
        "        padding_count = max_seq_len - len(input_id)\n",
        "        input_id = input_id + ([pad_token_id] * padding_count)\n",
        "        attention_mask = attention_mask + ([0] * padding_count)\n",
        "        token_type_id = [pad_token_id_for_segment] * max_seq_len\n",
        "        label_mask = label_mask + ([pad_token_id_for_label] * padding_count)\n",
        "\n",
        "        assert len(input_id) == max_seq_len, \"Error with input length {} vs {}\".format(len(input_id), max_seq_len)\n",
        "        assert len(attention_mask) == max_seq_len, \"Error with attention mask length {} vs {}\".format(len(attention_mask), max_seq_len)\n",
        "        assert len(token_type_id) == max_seq_len, \"Error with token type length {} vs {}\".format(len(token_type_id), max_seq_len)\n",
        "        assert len(label_mask) == max_seq_len, \"Error with labels length {} vs {}\".format(len(label_mask), max_seq_len)\n",
        "\n",
        "        input_ids.append(input_id)\n",
        "        attention_masks.append(attention_mask)\n",
        "        token_type_ids.append(token_type_id)\n",
        "        label_masks.append(label_mask)\n",
        "\n",
        "    input_ids = np.array(input_ids, dtype=int)\n",
        "    attention_masks = np.array(attention_masks, dtype=int)\n",
        "    token_type_ids = np.array(token_type_ids, dtype=int)\n",
        "    label_masks = np.asarray(label_masks, dtype=np.int32)\n",
        "\n",
        "    return (input_ids, attention_masks, token_type_ids), label_masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eM2tDJWz2eYo",
        "outputId": "6f86f834-7a1b-4394-cd6c-9576144ee6f7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5/5 [00:00<00:00, 359.85it/s]\n"
          ]
        }
      ],
      "source": [
        "X_pred, label_masks = convert_examples_to_features_for_prediction(test_data_sentence[:5], max_seq_len=128, tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "def remove_stopwords(sentence):\n",
        "  with open('/home/suyeon/code/capstone2/bert_ner/stop_words.txt',\"r\") as f:\n",
        "    stop_words = [line.rstrip('\\n') for line in f]\n",
        "  result = []\n",
        "  sentence = sentence.split(' ')\n",
        "  for i in sentence:\n",
        "      result.append(i)\n",
        "  return \" \".join(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "eun5TwgHi2J3"
      },
      "outputs": [],
      "source": [
        "def ner_prediction(examples, max_seq_len, tokenizer, lang='ko'):\n",
        "  examples = [sent.split() for sent in examples]\n",
        "  X_pred, label_masks = convert_examples_to_features_for_prediction(examples, max_seq_len=128, tokenizer=tokenizer)\n",
        "  \n",
        "  y_predicted = model.predict(X_pred)\n",
        "  y_predicted = np.argmax(y_predicted, axis = 2)\n",
        "\n",
        "  pred_list = []\n",
        "  result_list = []\n",
        "\n",
        "  for i in range(0, len(label_masks)):\n",
        "    for label_index, pred_index in zip(label_masks[i], y_predicted[i]):\n",
        "      if label_index != -100:\n",
        "        pred_list.append(index_to_tag[pred_index])\n",
        "\n",
        "  print(pred_list)\n",
        "  return \" \".join(pred_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "qpyCwTeamjOf"
      },
      "outputs": [],
      "source": [
        "sent1 = '급성 당뇨병이 생긴거 같아요'\n",
        "sent2 = '대장내시경을 통해서 우울증을 극복하자'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 683.89it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "2023-08-22 23:15:29.245021: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_32539\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'O O O O'"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ner_prediction([sent2], max_seq_len=128, tokenizer=tokenizer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Hi6ISgFPmLgO"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentences</th>\n",
              "      <th>morpheme</th>\n",
              "      <th>bio_tag</th>\n",
              "      <th>pos</th>\n",
              "      <th>format</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>성대결절은 발성의 문제가 있을 때 생기게 됩니다 .</td>\n",
              "      <td>XXXXO OOO OOO OO O OOO OOO O</td>\n",
              "      <td>B-DS O O O O O O O</td>\n",
              "      <td>(성대,NNG) / (결절,NNG) / (은,JX) / (발성,NNG) / (의,J...</td>\n",
              "      <td>Word | POS | Entity | BIO | Thought \\n성대결절은 |성...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>현재 허리 통증이 심한 상태라면 , 보다 정밀한 진찰을 받아 야 합니다 .</td>\n",
              "      <td>OO XX XXO OO OOOO O OO OOO OOO OO O OOO O</td>\n",
              "      <td>O B-BD B-ST O O O O O O O O O O</td>\n",
              "      <td>(현재,MAG) / (허리,NNG) / (통증,NNG) / (이,JKS) / (심한...</td>\n",
              "      <td>Word | POS | Entity | BIO | Thought \\n현재 |현재(M...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>시간이 가면서 이런 신호가 나온다면 감기 오고 있다는 증거가 될 수 있읍니다 .</td>\n",
              "      <td>OOO OOO OO OOO OOOO XX OO OOO OOO O O OOOO O</td>\n",
              "      <td>O O O O O B-ST O O O O O O O</td>\n",
              "      <td>(시간,NNG) / (이,JKS) / (가,VV) / (면서,EC) / (이런,MM...</td>\n",
              "      <td>Word | POS | Entity | BIO | Thought \\n시간이 |시간(...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>기관지 천식인지 , 기관지 과민성인지 , 기타 다른 호흡기 질환이나 심장 질환이 동...</td>\n",
              "      <td>XXX XXOO O XXX XXXOO O OO OO XXX OOOO XX OOO O...</td>\n",
              "      <td>B-DS I-DS O B-DS I-DS O O O B-BD O B-BD O O O ...</td>\n",
              "      <td>(기관지,NNG) / (천식,NNG) / (인지,VCP+EC) / (,,SC) / ...</td>\n",
              "      <td>Word | POS | Entity | BIO | Thought \\n기관지 |기관지...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>갑상선 기능 저하증이 조절되지 않으면 간 기능 검사상 수치가 상승되는 경우가 많고 ...</td>\n",
              "      <td>XXX XX XXXO OOOO OOO O OO OOO OOO OOOO OOO OO ...</td>\n",
              "      <td>B-DS I-DS I-DS O O O O O O O O O O B-DS O O O ...</td>\n",
              "      <td>(갑상선,NNG) / (기능,NNG) / (저하,NNG) / (증이,NNG) / (...</td>\n",
              "      <td>Word | POS | Entity | BIO | Thought \\n갑상선 |갑상선...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           sentences  \\\n",
              "0                       성대결절은 발성의 문제가 있을 때 생기게 됩니다 .   \n",
              "1          현재 허리 통증이 심한 상태라면 , 보다 정밀한 진찰을 받아 야 합니다 .   \n",
              "2       시간이 가면서 이런 신호가 나온다면 감기 오고 있다는 증거가 될 수 있읍니다 .   \n",
              "3  기관지 천식인지 , 기관지 과민성인지 , 기타 다른 호흡기 질환이나 심장 질환이 동...   \n",
              "4  갑상선 기능 저하증이 조절되지 않으면 간 기능 검사상 수치가 상승되는 경우가 많고 ...   \n",
              "\n",
              "                                            morpheme  \\\n",
              "0                       XXXXO OOO OOO OO O OOO OOO O   \n",
              "1          OO XX XXO OO OOOO O OO OOO OOO OO O OOO O   \n",
              "2       OOO OOO OO OOO OOOO XX OO OOO OOO O O OOOO O   \n",
              "3  XXX XXOO O XXX XXXOO O OO OO XXX OOOO XX OOO O...   \n",
              "4  XXX XX XXXO OOOO OOO O OO OOO OOO OOOO OOO OO ...   \n",
              "\n",
              "                                             bio_tag  \\\n",
              "0                                 B-DS O O O O O O O   \n",
              "1                    O B-BD B-ST O O O O O O O O O O   \n",
              "2                       O O O O O B-ST O O O O O O O   \n",
              "3  B-DS I-DS O B-DS I-DS O O O B-BD O B-BD O O O ...   \n",
              "4  B-DS I-DS I-DS O O O O O O O O O O B-DS O O O ...   \n",
              "\n",
              "                                                 pos  \\\n",
              "0  (성대,NNG) / (결절,NNG) / (은,JX) / (발성,NNG) / (의,J...   \n",
              "1  (현재,MAG) / (허리,NNG) / (통증,NNG) / (이,JKS) / (심한...   \n",
              "2  (시간,NNG) / (이,JKS) / (가,VV) / (면서,EC) / (이런,MM...   \n",
              "3  (기관지,NNG) / (천식,NNG) / (인지,VCP+EC) / (,,SC) / ...   \n",
              "4  (갑상선,NNG) / (기능,NNG) / (저하,NNG) / (증이,NNG) / (...   \n",
              "\n",
              "                                              format  \n",
              "0  Word | POS | Entity | BIO | Thought \\n성대결절은 |성...  \n",
              "1  Word | POS | Entity | BIO | Thought \\n현재 |현재(M...  \n",
              "2  Word | POS | Entity | BIO | Thought \\n시간이 |시간(...  \n",
              "3  Word | POS | Entity | BIO | Thought \\n기관지 |기관지...  \n",
              "4  Word | POS | Entity | BIO | Thought \\n갑상선 |갑상선...  "
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_df = pd.read_csv(\"./Data/test_data.csv\",encoding='cp949')\n",
        "test_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 547.70it/s]\n",
            "2023-08-22 23:15:30.668036: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_32663\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 398.66it/s]\n",
            "2023-08-22 23:15:30.787640: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_32787\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 500.22it/s]\n",
            "2023-08-22 23:15:30.902421: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_32911\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 188.44it/s]\n",
            "2023-08-22 23:15:31.016979: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_33035\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 206.51it/s]\n",
            "2023-08-22 23:15:31.121039: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_33159\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 415.20it/s]\n",
            "2023-08-22 23:15:31.215933: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_33283\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 736.75it/s]\n",
            "2023-08-22 23:15:31.317010: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_33407\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 754.37it/s]\n",
            "2023-08-22 23:15:31.409869: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_33531\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 442.20it/s]\n",
            "2023-08-22 23:15:31.499689: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_33655\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 836.19it/s]\n",
            "2023-08-22 23:15:31.589825: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_33779\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 813.01it/s]\n",
            "2023-08-22 23:15:31.705506: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_33903\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 223.88it/s]\n",
            "2023-08-22 23:15:31.822986: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_34027\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 397.23it/s]\n",
            "2023-08-22 23:15:31.926614: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_34151\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 850.60it/s]\n",
            "2023-08-22 23:15:32.014970: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_34275\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 213.86it/s]\n",
            "2023-08-22 23:15:32.133662: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_34399\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 591.58it/s]\n",
            "2023-08-22 23:15:32.248818: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_34523\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 201.54it/s]\n",
            "2023-08-22 23:15:32.360252: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_34647\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 1137.90it/s]\n",
            "2023-08-22 23:15:32.455638: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_34771\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 371.08it/s]\n",
            "2023-08-22 23:15:32.564205: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_34895\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 318.96it/s]\n",
            "2023-08-22 23:15:32.679271: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_35019\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 164.23it/s]\n",
            "2023-08-22 23:15:32.790131: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_35143\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 845.11it/s]\n",
            "2023-08-22 23:15:32.882956: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_35267\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 338.85it/s]\n",
            "2023-08-22 23:15:32.994094: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_35391\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 365.42it/s]\n",
            "2023-08-22 23:15:33.090260: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_35515\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 952.60it/s]\n",
            "2023-08-22 23:15:33.193983: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_35639\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 528.98it/s]\n",
            "2023-08-22 23:15:33.296381: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_35763\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 661.35it/s]\n",
            "2023-08-22 23:15:33.722256: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_35887\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 296.52it/s]\n",
            "2023-08-22 23:15:33.814432: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_36011\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 335.52it/s]\n",
            "2023-08-22 23:15:33.906104: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_36135\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 861.25it/s]\n",
            "2023-08-22 23:15:34.005703: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_36259\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 276.36it/s]\n",
            "2023-08-22 23:15:34.114217: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_36383\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 357.91it/s]\n",
            "2023-08-22 23:15:34.204723: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_36507\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 321.62it/s]\n",
            "2023-08-22 23:15:34.309549: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_36631\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 426.94it/s]\n",
            "2023-08-22 23:15:34.408735: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_36755\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 280.57it/s]\n",
            "2023-08-22 23:15:34.530808: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_36879\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 386.57it/s]\n",
            "2023-08-22 23:15:34.634750: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_37003\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 384.20it/s]\n",
            "2023-08-22 23:15:34.729309: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_37127\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 594.60it/s]\n",
            "2023-08-22 23:15:34.820973: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_37251\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 686.92it/s]\n",
            "2023-08-22 23:15:34.917228: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_37375\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 335.62it/s]\n",
            "2023-08-22 23:15:35.011799: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_37499\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 492.23it/s]\n",
            "2023-08-22 23:15:35.116761: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_37623\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 1269.85it/s]\n",
            "2023-08-22 23:15:35.212832: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_37747\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 576.70it/s]\n",
            "2023-08-22 23:15:35.309205: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_37871\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 388.07it/s]\n",
            "2023-08-22 23:15:35.401338: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_37995\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 797.55it/s]\n",
            "2023-08-22 23:15:35.496705: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_38119\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 504.24it/s]\n",
            "2023-08-22 23:15:35.588206: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_38243\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 358.30it/s]\n",
            "2023-08-22 23:15:35.678840: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_38367\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 832.20it/s]\n",
            "2023-08-22 23:15:35.769567: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_38491\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 1526.31it/s]\n",
            "2023-08-22 23:15:35.860827: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_38615\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['B-BD', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 602.02it/s]\n",
            "2023-08-22 23:15:35.974977: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_38739\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 487.65it/s]\n",
            "2023-08-22 23:15:36.086743: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_38863\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 575.75it/s]\n",
            "2023-08-22 23:15:36.183478: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_38987\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 499.44it/s]\n",
            "2023-08-22 23:15:36.276423: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_39111\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 312.10it/s]\n",
            "2023-08-22 23:15:36.381167: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_39235\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 658.14it/s]\n",
            "2023-08-22 23:15:36.501950: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_39359\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 648.07it/s]\n",
            "2023-08-22 23:15:36.603733: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_39483\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 715.39it/s]\n",
            "2023-08-22 23:15:36.697696: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_39607\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 1449.81it/s]\n",
            "2023-08-22 23:15:36.791343: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_39731\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 475.60it/s]\n",
            "2023-08-22 23:15:36.894388: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_39855\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 290.73it/s]\n",
            "2023-08-22 23:15:36.997618: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_39979\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 369.77it/s]\n",
            "2023-08-22 23:15:37.088119: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_40103\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 648.37it/s]\n",
            "2023-08-22 23:15:37.180511: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_40227\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 487.54it/s]\n",
            "2023-08-22 23:15:37.275803: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_40351\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 138.45it/s]\n",
            "2023-08-22 23:15:37.381543: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_40475\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 976.33it/s]\n",
            "2023-08-22 23:15:37.469879: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_40599\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 965.98it/s]\n",
            "2023-08-22 23:15:37.562521: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_40723\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 499.80it/s]\n",
            "2023-08-22 23:15:37.660913: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_40847\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 940.43it/s]\n",
            "2023-08-22 23:15:37.750495: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_40971\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 1172.25it/s]\n",
            "2023-08-22 23:15:37.842138: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_41095\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 147.37it/s]\n",
            "2023-08-22 23:15:37.947633: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_41219\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 863.74it/s]\n",
            "2023-08-22 23:15:38.039316: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_41343\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 771.58it/s]\n",
            "2023-08-22 23:15:38.128107: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_41467\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 792.87it/s]\n",
            "2023-08-22 23:15:38.214888: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_41591\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 963.54it/s]\n",
            "2023-08-22 23:15:38.315085: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_41715\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 781.21it/s]\n",
            "2023-08-22 23:15:38.407731: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_41839\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 1340.46it/s]\n",
            "2023-08-22 23:15:38.494014: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_41963\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 540.29it/s]\n",
            "2023-08-22 23:15:38.584613: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_42087\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 990.62it/s]\n",
            "2023-08-22 23:15:38.671585: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_42211\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 236.79it/s]\n",
            "2023-08-22 23:15:38.771126: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_42335\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 550.22it/s]\n",
            "2023-08-22 23:15:38.882651: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_42459\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 3524.63it/s]\n",
            "2023-08-22 23:15:38.972405: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_42583\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 688.38it/s]\n",
            "2023-08-22 23:15:39.069348: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_42707\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 203.11it/s]\n",
            "2023-08-22 23:15:39.172004: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_42831\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 306.22it/s]\n",
            "2023-08-22 23:15:39.269027: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_42955\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 300.24it/s]\n",
            "2023-08-22 23:15:39.361991: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_43079\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 407.77it/s]\n",
            "2023-08-22 23:15:39.450748: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_43203\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 1567.96it/s]\n",
            "2023-08-22 23:15:39.540281: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_43327\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 217.11it/s]\n",
            "2023-08-22 23:15:39.631529: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_43451\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 368.24it/s]\n",
            "2023-08-22 23:15:39.731060: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_43575\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 372.46it/s]\n",
            "2023-08-22 23:15:39.824162: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_43699\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 1519.12it/s]\n",
            "2023-08-22 23:15:39.914556: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_43823\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 269.75it/s]\n",
            "2023-08-22 23:15:40.015929: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_43947\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 899.49it/s]\n",
            "2023-08-22 23:15:40.107228: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_44071\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 566.80it/s]\n",
            "2023-08-22 23:15:40.199007: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_44195\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 468.27it/s]\n",
            "2023-08-22 23:15:40.290736: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_44319\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 431.38it/s]\n",
            "2023-08-22 23:15:40.392178: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_44443\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 1188.19it/s]\n",
            "2023-08-22 23:15:40.483217: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_44567\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 546.42it/s]\n",
            "2023-08-22 23:15:40.576719: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_44691\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 252.06it/s]\n",
            "2023-08-22 23:15:40.689430: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_44815\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 819.36it/s]\n",
            "2023-08-22 23:15:40.783589: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_44939\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 1026.00it/s]\n",
            "2023-08-22 23:15:40.877270: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_45063\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 379.40it/s]\n",
            "2023-08-22 23:15:41.005126: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_45187\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 684.56it/s]\n",
            "2023-08-22 23:15:41.116258: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_45311\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 305.20it/s]\n",
            "2023-08-22 23:15:41.210939: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_45435\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 974.51it/s]\n",
            "2023-08-22 23:15:41.300580: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_45559\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 1457.37it/s]\n",
            "2023-08-22 23:15:41.392561: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_45683\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 283.36it/s]\n",
            "2023-08-22 23:15:41.493228: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_45807\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 442.34it/s]\n",
            "2023-08-22 23:15:41.601345: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_45931\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 341.14it/s]\n",
            "2023-08-22 23:15:41.710853: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_46055\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 498.61it/s]\n",
            "2023-08-22 23:15:41.808226: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_46179\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 449.89it/s]\n",
            "2023-08-22 23:15:41.911026: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_46303\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 667.14it/s]\n",
            "2023-08-22 23:15:42.016650: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_46427\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 382.31it/s]\n",
            "2023-08-22 23:15:42.110827: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_46551\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 1597.22it/s]\n",
            "2023-08-22 23:15:42.217649: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_46675\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 522.20it/s]\n",
            "2023-08-22 23:15:42.323063: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_46799\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 795.28it/s]\n",
            "2023-08-22 23:15:42.414880: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_46923\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 244.88it/s]\n",
            "2023-08-22 23:15:42.509088: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_47047\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 350.61it/s]\n",
            "2023-08-22 23:15:42.604854: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_47171\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 315.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-08-22 23:15:42.711888: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_47295\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 806.13it/s]\n",
            "2023-08-22 23:15:42.802612: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_47419\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 564.81it/s]\n",
            "2023-08-22 23:15:42.897617: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_47543\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 437.64it/s]\n",
            "2023-08-22 23:15:43.006138: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_47667\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 191.03it/s]\n",
            "2023-08-22 23:15:43.117185: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_47791\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 811.59it/s]\n",
            "2023-08-22 23:15:43.208496: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_47915\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 1233.98it/s]\n",
            "2023-08-22 23:15:43.299036: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_48039\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 823.87it/s]\n",
            "2023-08-22 23:15:43.415895: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_48163\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 621.93it/s]\n",
            "2023-08-22 23:15:43.536917: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_48287\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 547.63it/s]\n",
            "2023-08-22 23:15:43.633504: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_48411\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 789.89it/s]\n",
            "2023-08-22 23:15:43.723916: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_48535\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 455.21it/s]\n",
            "2023-08-22 23:15:43.831717: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_48659\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 658.24it/s]\n",
            "2023-08-22 23:15:43.935773: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_48783\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 501.47it/s]\n",
            "2023-08-22 23:15:44.041977: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_48907\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 245.76it/s]\n",
            "2023-08-22 23:15:44.152162: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_49031\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 667.56it/s]\n",
            "2023-08-22 23:15:44.263714: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_49155\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 306.00it/s]\n",
            "2023-08-22 23:15:44.380312: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_49279\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 1267.93it/s]\n",
            "2023-08-22 23:15:44.478002: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_49403\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 691.90it/s]\n",
            "2023-08-22 23:15:44.570742: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_49527\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 327.83it/s]\n",
            "2023-08-22 23:15:44.681047: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_49651\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 221.84it/s]\n",
            "2023-08-22 23:15:44.815499: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_49775\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 418.51it/s]\n",
            "2023-08-22 23:15:44.909867: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_49899\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 632.15it/s]\n",
            "2023-08-22 23:15:44.998801: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_50023\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 1293.74it/s]\n",
            "2023-08-22 23:15:45.085941: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_50147\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 947.65it/s]\n",
            "2023-08-22 23:15:45.179945: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_50271\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 418.09it/s]\n",
            "2023-08-22 23:15:45.277807: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_50395\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 225.52it/s]\n",
            "2023-08-22 23:15:45.384782: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_50519\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 812.22it/s]\n",
            "2023-08-22 23:15:45.473663: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_50643\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 384.55it/s]\n",
            "2023-08-22 23:15:45.569284: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_50767\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 420.10it/s]\n",
            "2023-08-22 23:15:45.670121: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_50891\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 563.45it/s]\n",
            "2023-08-22 23:15:45.777777: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_51015\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 629.78it/s]\n",
            "2023-08-22 23:15:45.878945: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_51139\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 666.71it/s]\n",
            "2023-08-22 23:15:45.976901: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_51263\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 419.93it/s]\n",
            "2023-08-22 23:15:46.087464: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_51387\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'B-BD', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 317.10it/s]\n",
            "2023-08-22 23:15:46.194643: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_51511\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 403.96it/s]\n",
            "2023-08-22 23:15:46.293103: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_51635\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 466.40it/s]\n",
            "2023-08-22 23:15:46.388439: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_51759\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 237.36it/s]\n",
            "2023-08-22 23:15:46.491540: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_51883\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 601.94it/s]\n",
            "2023-08-22 23:15:46.594485: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_52007\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 767.91it/s]\n",
            "2023-08-22 23:15:46.688621: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_52131\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 632.91it/s]\n",
            "2023-08-22 23:15:46.786037: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_52255\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 982.27it/s]\n",
            "2023-08-22 23:15:46.879975: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_52379\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 409.12it/s]\n",
            "2023-08-22 23:15:46.973545: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_52503\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 591.58it/s]\n",
            "2023-08-22 23:15:47.079242: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_52627\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 942.96it/s]\n",
            "2023-08-22 23:15:47.177115: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_52751\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 723.78it/s]\n",
            "2023-08-22 23:15:47.267748: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_52875\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 482.27it/s]\n",
            "2023-08-22 23:15:47.362782: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_52999\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 611.06it/s]\n",
            "2023-08-22 23:15:47.477917: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_53123\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 416.76it/s]\n",
            "2023-08-22 23:15:47.580925: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_53247\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 314.09it/s]\n",
            "2023-08-22 23:15:47.678229: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_53371\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 613.92it/s]\n",
            "2023-08-22 23:15:47.778343: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_53495\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'B-BD', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 618.26it/s]\n",
            "2023-08-22 23:15:47.872658: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_53619\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 540.43it/s]\n",
            "2023-08-22 23:15:47.991548: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_53743\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 251.99it/s]\n",
            "2023-08-22 23:15:48.096262: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_53867\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 629.02it/s]\n",
            "2023-08-22 23:15:48.203967: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_53991\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 327.76it/s]\n",
            "2023-08-22 23:15:48.299080: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_54115\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 365.10it/s]\n",
            "2023-08-22 23:15:48.411629: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_54239\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 1123.27it/s]\n",
            "2023-08-22 23:15:48.504119: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_54363\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 804.74it/s]\n",
            "2023-08-22 23:15:48.595614: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_54487\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 223.46it/s]\n",
            "2023-08-22 23:15:48.703477: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_54611\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 329.61it/s]\n",
            "2023-08-22 23:15:48.809728: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_54735\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 552.03it/s]\n",
            "2023-08-22 23:15:48.900253: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_54859\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 334.53it/s]\n",
            "2023-08-22 23:15:49.007039: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_54983\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 534.78it/s]\n",
            "2023-08-22 23:15:49.105102: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_55107\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 246.19it/s]\n",
            "2023-08-22 23:15:49.218879: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_55231\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 622.30it/s]\n",
            "2023-08-22 23:15:49.324367: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_55355\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 364.28it/s]\n",
            "2023-08-22 23:15:49.420240: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_55479\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 286.69it/s]\n",
            "2023-08-22 23:15:49.521534: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_55603\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 483.66it/s]\n",
            "2023-08-22 23:15:49.618343: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_55727\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 442.81it/s]\n",
            "2023-08-22 23:15:49.708951: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_55851\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 598.93it/s]\n",
            "2023-08-22 23:15:49.797969: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_55975\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 210.05it/s]\n",
            "2023-08-22 23:15:49.902214: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_56099\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 349.26it/s]\n",
            "2023-08-22 23:15:50.001413: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_56223\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 632.43it/s]\n",
            "2023-08-22 23:15:50.089908: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_56347\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 342.98it/s]\n",
            "2023-08-22 23:15:50.179905: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_56471\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 323.53it/s]\n",
            "2023-08-22 23:15:50.273978: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_56595\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 322.24it/s]\n",
            "2023-08-22 23:15:50.393263: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_56719\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 494.26it/s]\n",
            "2023-08-22 23:15:50.500291: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_56843\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 478.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-08-22 23:15:50.594553: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_56967\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n",
            "100%|██████████| 1/1 [00:00<00:00, 787.22it/s]\n",
            "2023-08-22 23:15:50.686284: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_57091\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 1003.90it/s]\n",
            "2023-08-22 23:15:50.778224: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_57215\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 550.22it/s]\n",
            "2023-08-22 23:15:50.871517: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_57339\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 212.74it/s]\n",
            "2023-08-22 23:15:50.976922: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_57463\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 764.97it/s]\n",
            "2023-08-22 23:15:51.069896: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_57587\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 384.69it/s]\n",
            "2023-08-22 23:15:51.174009: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_57711\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 1090.28it/s]\n",
            "2023-08-22 23:15:51.263573: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_57835\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 635.98it/s]\n",
            "2023-08-22 23:15:51.363373: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_57959\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 856.16it/s]\n",
            "2023-08-22 23:15:51.451620: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_58083\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 492.81it/s]\n",
            "2023-08-22 23:15:51.549910: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_58207\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 522.20it/s]\n",
            "2023-08-22 23:15:51.639734: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_58331\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 697.19it/s]\n",
            "2023-08-22 23:15:51.743183: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_58455\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 848.02it/s]\n",
            "2023-08-22 23:15:51.839257: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_58579\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 1462.45it/s]\n",
            "2023-08-22 23:15:51.941081: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_58703\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 422.81it/s]\n",
            "2023-08-22 23:15:52.037028: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_58827\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 524.94it/s]\n",
            "2023-08-22 23:15:52.131699: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_58951\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 697.31it/s]\n",
            "2023-08-22 23:15:52.223336: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_59075\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 457.49it/s]\n",
            "2023-08-22 23:15:52.342936: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_59199\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 210.10it/s]\n",
            "2023-08-22 23:15:52.434458: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_59323\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 459.85it/s]\n",
            "2023-08-22 23:15:52.529336: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_59447\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 406.07it/s]\n",
            "2023-08-22 23:15:52.623375: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_59571\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 761.35it/s]\n",
            "2023-08-22 23:15:52.720403: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_59695\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 347.18it/s]\n",
            "2023-08-22 23:15:52.820087: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_59819\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 544.43it/s]\n",
            "2023-08-22 23:15:52.910854: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_59943\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 439.79it/s]\n",
            "2023-08-22 23:15:53.001766: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_60067\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 652.91it/s]\n",
            "2023-08-22 23:15:53.100321: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_60191\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 464.02it/s]\n",
            "2023-08-22 23:15:53.199450: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_60315\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 308.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-08-22 23:15:53.302441: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_60439\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 2144.33it/s]\n",
            "2023-08-22 23:15:53.399989: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_60563\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 159.83it/s]\n",
            "2023-08-22 23:15:53.516898: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_60687\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 1001.03it/s]\n",
            "2023-08-22 23:15:53.608408: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_60811\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 629.30it/s]\n",
            "2023-08-22 23:15:53.706407: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_60935\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 698.82it/s]\n",
            "2023-08-22 23:15:53.800961: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_61059\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 231.19it/s]\n",
            "2023-08-22 23:15:53.911326: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_61183\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 295.39it/s]\n",
            "2023-08-22 23:15:54.013895: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_61307\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 473.29it/s]\n",
            "2023-08-22 23:15:54.119528: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_61431\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 742.22it/s]\n",
            "2023-08-22 23:15:54.226003: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_61555\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 998.64it/s]\n",
            "2023-08-22 23:15:54.326085: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_61679\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 818.40it/s]\n",
            "2023-08-22 23:15:54.418088: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_61803\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 645.28it/s]\n",
            "2023-08-22 23:15:54.500814: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_61927\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 785.60it/s]\n",
            "2023-08-22 23:15:54.590808: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_62051\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 612.04it/s]\n",
            "2023-08-22 23:15:54.701833: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_62175\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 460.91it/s]\n",
            "2023-08-22 23:15:54.817264: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_62299\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 1423.73it/s]\n",
            "2023-08-22 23:15:54.924513: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_62423\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 772.29it/s]\n",
            "2023-08-22 23:15:55.017357: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_62547\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 333.46it/s]\n",
            "2023-08-22 23:15:55.136884: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_62671\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 413.15it/s]\n",
            "2023-08-22 23:15:55.235019: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_62795\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 561.04it/s]\n",
            "2023-08-22 23:15:55.331804: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_62919\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 436.59it/s]\n",
            "2023-08-22 23:15:55.439779: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_63043\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 409.68it/s]\n",
            "2023-08-22 23:15:55.554826: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_63167\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 436.72it/s]\n",
            "2023-08-22 23:15:55.660339: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_63291\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 445.68it/s]\n",
            "2023-08-22 23:15:55.781221: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_63415\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 1059.70it/s]\n",
            "2023-08-22 23:15:55.882666: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_63539\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 310.37it/s]\n",
            "2023-08-22 23:15:55.989051: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_63663\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 527.45it/s]\n",
            "2023-08-22 23:15:56.082223: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_63787\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 577.41it/s]\n",
            "2023-08-22 23:15:56.172496: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_63911\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 762.60it/s]\n",
            "2023-08-22 23:15:56.267057: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_64035\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 3474.98it/s]\n",
            "2023-08-22 23:15:56.365242: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_64159\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 428.08it/s]\n",
            "2023-08-22 23:15:56.474679: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_64283\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 539.81it/s]\n",
            "2023-08-22 23:15:56.571969: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_64407\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 253.19it/s]\n",
            "2023-08-22 23:15:56.675522: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_64531\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 705.87it/s]\n",
            "2023-08-22 23:15:56.772789: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_64655\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 586.45it/s]\n",
            "2023-08-22 23:15:56.860969: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_64779\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 616.45it/s]\n",
            "2023-08-22 23:15:56.954799: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_64903\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 937.07it/s]\n",
            "2023-08-22 23:15:57.038558: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_65027\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 658.76it/s]\n",
            "2023-08-22 23:15:57.129341: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_65151\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 593.67it/s]\n",
            "2023-08-22 23:15:57.227541: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_65275\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 319.93it/s]\n",
            "2023-08-22 23:15:57.336623: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_65399\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 765.94it/s]\n",
            "2023-08-22 23:15:57.430185: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_65523\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 257.94it/s]\n",
            "2023-08-22 23:15:57.535953: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_65647\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 481.83it/s]\n",
            "2023-08-22 23:15:57.651540: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_65771\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 1228.92it/s]\n",
            "2023-08-22 23:15:57.743689: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_65895\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 345.98it/s]\n",
            "2023-08-22 23:15:57.848468: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_66019\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 694.08it/s]\n",
            "2023-08-22 23:15:57.945991: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_66143\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 350.08it/s]\n",
            "2023-08-22 23:15:58.051229: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_66267\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 467.12it/s]\n",
            "2023-08-22 23:15:58.147952: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_66391\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 424.35it/s]\n",
            "2023-08-22 23:15:58.241081: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_66515\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 511.56it/s]\n",
            "2023-08-22 23:15:58.335714: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_66639\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 543.37it/s]\n",
            "2023-08-22 23:15:58.448319: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_66763\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 925.49it/s]\n",
            "2023-08-22 23:15:58.549600: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_66887\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 439.38it/s]\n",
            "2023-08-22 23:15:58.640712: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_67011\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 1158.65it/s]\n",
            "2023-08-22 23:15:58.736561: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_67135\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 669.59it/s]\n",
            "2023-08-22 23:15:58.836399: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_67259\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 1179.50it/s]\n",
            "2023-08-22 23:15:58.923584: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_67383\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 405.52it/s]\n",
            "2023-08-22 23:15:59.040954: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_67507\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 328.97it/s]\n",
            "2023-08-22 23:15:59.155421: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_67631\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 244.22it/s]\n",
            "2023-08-22 23:15:59.265387: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_67755\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 420.95it/s]\n",
            "2023-08-22 23:15:59.361217: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_67879\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 350.11it/s]\n",
            "2023-08-22 23:15:59.454461: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_68003\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 385.40it/s]\n",
            "2023-08-22 23:15:59.552483: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_68127\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 409.64it/s]\n",
            "2023-08-22 23:15:59.644418: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_68251\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 536.91it/s]\n",
            "2023-08-22 23:15:59.745022: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_68375\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 166.98it/s]\n",
            "2023-08-22 23:15:59.846125: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_68499\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 398.62it/s]\n",
            "2023-08-22 23:15:59.945504: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_68623\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 496.31it/s]\n",
            "2023-08-22 23:16:00.058137: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_68747\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 475.92it/s]\n",
            "2023-08-22 23:16:00.167352: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_68871\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 959.58it/s]\n",
            "2023-08-22 23:16:00.260433: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_68995\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 354.25it/s]\n",
            "2023-08-22 23:16:00.365757: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_69119\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 821.12it/s]\n",
            "2023-08-22 23:16:00.461656: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_69243\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 395.61it/s]\n",
            "2023-08-22 23:16:00.567547: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_69367\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 700.57it/s]\n",
            "2023-08-22 23:16:00.674283: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_69491\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 585.06it/s]\n",
            "2023-08-22 23:16:00.763729: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_69615\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 326.63it/s]\n",
            "2023-08-22 23:16:00.869411: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_69739\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 568.56it/s]\n",
            "2023-08-22 23:16:00.981193: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_69863\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 332.04it/s]\n",
            "2023-08-22 23:16:01.082498: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_69987\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 463.41it/s]\n",
            "2023-08-22 23:16:01.195986: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_70111\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 561.56it/s]\n",
            "2023-08-22 23:16:01.289637: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_70235\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 363.52it/s]\n",
            "2023-08-22 23:16:01.386623: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_70359\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 356.93it/s]\n",
            "2023-08-22 23:16:01.481084: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_70483\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 1088.58it/s]\n",
            "2023-08-22 23:16:01.582994: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_70607\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 864.63it/s]\n",
            "2023-08-22 23:16:01.670867: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_70731\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 277.40it/s]\n",
            "2023-08-22 23:16:01.792971: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_70855\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 715.63it/s]\n",
            "2023-08-22 23:16:01.888715: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_70979\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 368.44it/s]\n",
            "2023-08-22 23:16:01.997268: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_71103\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 704.10it/s]\n",
            "2023-08-22 23:16:02.087266: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_71227\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 308.09it/s]\n",
            "2023-08-22 23:16:02.199617: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_71351\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 373.59it/s]\n",
            "2023-08-22 23:16:02.298862: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_71475\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 293.49it/s]\n",
            "2023-08-22 23:16:02.420393: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_71599\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 510.32it/s]\n",
            "2023-08-22 23:16:02.532040: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_71723\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 578.84it/s]\n",
            "2023-08-22 23:16:02.630518: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_71847\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 350.17it/s]\n",
            "2023-08-22 23:16:02.725592: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_71971\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 330.89it/s]\n",
            "2023-08-22 23:16:02.839182: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_72095\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 1647.41it/s]\n",
            "2023-08-22 23:16:02.925020: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_72219\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 648.77it/s]\n",
            "2023-08-22 23:16:03.026758: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_72343\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 695.34it/s]\n",
            "2023-08-22 23:16:03.123634: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_72467\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 667.25it/s]\n",
            "2023-08-22 23:16:03.219485: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_72591\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 355.63it/s]\n",
            "2023-08-22 23:16:03.313951: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_72715\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 247.16it/s]\n",
            "2023-08-22 23:16:03.421776: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_72839\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 492.29it/s]\n",
            "2023-08-22 23:16:03.520671: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_72963\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 1113.43it/s]\n",
            "2023-08-22 23:16:03.618250: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_73087\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 357.54it/s]\n",
            "2023-08-22 23:16:03.723536: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_73211\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 1168.98it/s]\n",
            "2023-08-22 23:16:03.811024: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_73335\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 952.39it/s]\n",
            "2023-08-22 23:16:03.903925: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_73459\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 316.34it/s]\n",
            "2023-08-22 23:16:04.009250: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_73583\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 1370.24it/s]\n",
            "2023-08-22 23:16:04.096128: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_73707\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 441.55it/s]\n",
            "2023-08-22 23:16:04.194098: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_73831\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 233.90it/s]\n",
            "2023-08-22 23:16:04.289404: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_73955\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 275.49it/s]\n",
            "2023-08-22 23:16:04.399839: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_74079\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 460.00it/s]\n",
            "2023-08-22 23:16:04.490013: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_74203\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 416.47it/s]\n",
            "2023-08-22 23:16:04.584973: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_74327\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 209.78it/s]\n",
            "2023-08-22 23:16:04.690616: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_74451\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 1308.27it/s]\n",
            "2023-08-22 23:16:04.781828: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_74575\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 478.47it/s]\n",
            "2023-08-22 23:16:04.875171: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_74699\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 136.12it/s]\n",
            "2023-08-22 23:16:04.984426: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_74823\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 1117.88it/s]\n",
            "2023-08-22 23:16:05.073275: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_74947\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 213.41it/s]\n",
            "2023-08-22 23:16:05.191896: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_75071\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 958.70it/s]\n",
            "2023-08-22 23:16:05.283756: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_75195\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 394.98it/s]\n",
            "2023-08-22 23:16:05.377015: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_75319\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 464.49it/s]\n",
            "2023-08-22 23:16:05.479107: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_75443\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 653.42it/s]\n",
            "2023-08-22 23:16:05.574188: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_75567\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 584.00it/s]\n",
            "2023-08-22 23:16:05.664936: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_75691\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 330.42it/s]\n",
            "2023-08-22 23:16:05.768505: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_75815\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 421.96it/s]\n",
            "2023-08-22 23:16:05.862881: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_75939\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 440.81it/s]\n",
            "2023-08-22 23:16:05.959116: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_76063\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 297.03it/s]\n",
            "2023-08-22 23:16:06.051028: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_76187\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 618.36it/s]\n",
            "2023-08-22 23:16:06.141594: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_76311\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 313.83it/s]\n",
            "2023-08-22 23:16:06.234122: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_76435\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 382.52it/s]\n",
            "2023-08-22 23:16:06.341851: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_76559\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 479.62it/s]\n",
            "2023-08-22 23:16:06.432311: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_76683\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 848.36it/s]\n",
            "2023-08-22 23:16:06.521541: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_76807\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 794.68it/s]\n",
            "2023-08-22 23:16:06.610530: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_76931\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 342.36it/s]\n",
            "2023-08-22 23:16:06.703128: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_77055\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 1013.85it/s]\n",
            "2023-08-22 23:16:06.809647: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_77179\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 827.93it/s]\n",
            "2023-08-22 23:16:06.924088: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_77303\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 281.74it/s]\n",
            "2023-08-22 23:16:07.026742: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_77427\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 431.07it/s]\n",
            "2023-08-22 23:16:07.156365: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_77551\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 265.08it/s]\n",
            "2023-08-22 23:16:07.254232: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_77675\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 343.06it/s]\n",
            "2023-08-22 23:16:07.351320: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_77799\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 410.80it/s]\n",
            "2023-08-22 23:16:07.447945: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_77923\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 402.45it/s]\n",
            "2023-08-22 23:16:07.542901: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_78047\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 271.25it/s]\n",
            "2023-08-22 23:16:07.646236: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_78171\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 770.30it/s]\n",
            "2023-08-22 23:16:07.739232: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_78295\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 553.12it/s]\n",
            "2023-08-22 23:16:07.829495: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_78419\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 683.33it/s]\n",
            "2023-08-22 23:16:07.930084: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_78543\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 678.03it/s]\n",
            "2023-08-22 23:16:08.020380: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_78667\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 516.03it/s]\n",
            "2023-08-22 23:16:08.116053: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_78791\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 2387.20it/s]\n",
            "2023-08-22 23:16:08.204317: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_78915\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 452.46it/s]\n",
            "2023-08-22 23:16:08.312846: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_79039\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 786.04it/s]\n",
            "2023-08-22 23:16:08.405067: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_79163\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 569.65it/s]\n",
            "2023-08-22 23:16:08.495814: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_79287\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 505.76it/s]\n",
            "2023-08-22 23:16:08.590296: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_79411\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 596.88it/s]\n",
            "2023-08-22 23:16:08.687279: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_79535\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 282.06it/s]\n",
            "2023-08-22 23:16:08.784285: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_79659\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 422.73it/s]\n",
            "2023-08-22 23:16:08.901749: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_79783\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 433.39it/s]\n",
            "2023-08-22 23:16:08.994826: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_79907\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 753.96it/s]\n",
            "2023-08-22 23:16:09.091699: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_80031\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 407.57it/s]\n",
            "2023-08-22 23:16:09.188693: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_80155\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 849.91it/s]\n",
            "2023-08-22 23:16:09.277720: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_80279\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 646.57it/s]\n",
            "2023-08-22 23:16:09.366145: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_80403\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 578.05it/s]\n",
            "2023-08-22 23:16:09.459729: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_80527\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 492.12it/s]\n",
            "2023-08-22 23:16:09.548462: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_80651\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 337.73it/s]\n",
            "2023-08-22 23:16:09.646794: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_80775\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 417.63it/s]\n",
            "2023-08-22 23:16:09.755254: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_80899\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 880.05it/s]\n",
            "2023-08-22 23:16:09.865897: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_81023\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 482.77it/s]\n",
            "2023-08-22 23:16:09.968436: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_81147\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 1109.60it/s]\n",
            "2023-08-22 23:16:10.061612: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_81271\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 917.39it/s]\n",
            "2023-08-22 23:16:10.154376: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_81395\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 530.19it/s]\n",
            "2023-08-22 23:16:10.253292: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_81519\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 240.24it/s]\n",
            "2023-08-22 23:16:10.361803: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_81643\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 356.36it/s]\n",
            "2023-08-22 23:16:10.477956: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_81767\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 415.61it/s]\n",
            "2023-08-22 23:16:10.569935: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_81891\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 642.81it/s]\n",
            "2023-08-22 23:16:10.665782: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_82015\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 529.25it/s]\n",
            "2023-08-22 23:16:10.761424: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_82139\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 264.16it/s]\n",
            "2023-08-22 23:16:10.865508: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_82263\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 317.94it/s]\n",
            "2023-08-22 23:16:10.959277: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_82387\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 199.03it/s]\n",
            "2023-08-22 23:16:11.063472: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_82511\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 849.39it/s]\n",
            "2023-08-22 23:16:11.159631: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_82635\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 1391.15it/s]\n",
            "2023-08-22 23:16:11.246094: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_82759\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 494.84it/s]\n",
            "2023-08-22 23:16:11.343478: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_82883\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 454.72it/s]\n",
            "2023-08-22 23:16:11.442280: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_83007\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 453.34it/s]\n",
            "2023-08-22 23:16:11.529344: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_83131\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 1101.73it/s]\n",
            "2023-08-22 23:16:11.616851: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_83255\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 307.30it/s]\n",
            "2023-08-22 23:16:11.717925: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_83379\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 618.17it/s]\n",
            "2023-08-22 23:16:11.827110: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_83503\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 312.38it/s]\n",
            "2023-08-22 23:16:11.923692: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_83627\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 2187.95it/s]\n",
            "2023-08-22 23:16:12.013747: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_83751\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 432.76it/s]\n",
            "2023-08-22 23:16:12.121936: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_83875\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 466.09it/s]\n",
            "2023-08-22 23:16:12.217549: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_83999\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 479.73it/s]\n",
            "2023-08-22 23:16:12.305770: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_84123\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 1071.34it/s]\n",
            "2023-08-22 23:16:12.394813: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_84247\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 999.83it/s]\n",
            "2023-08-22 23:16:12.486939: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_84371\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 309.43it/s]\n",
            "2023-08-22 23:16:12.610175: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_84495\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 708.14it/s]\n",
            "2023-08-22 23:16:12.702301: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_84619\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 841.38it/s]\n",
            "2023-08-22 23:16:12.789303: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_84743\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 296.96it/s]\n",
            "2023-08-22 23:16:12.895586: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_84867\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 208.86it/s]\n",
            "2023-08-22 23:16:13.008524: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_84991\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 521.36it/s]\n",
            "2023-08-22 23:16:13.101779: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_85115\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 875.64it/s]\n",
            "2023-08-22 23:16:13.190911: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_85239\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 888.44it/s]\n",
            "2023-08-22 23:16:13.294995: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_85363\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 744.20it/s]\n",
            "2023-08-22 23:16:13.390893: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_85487\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 244.79it/s]\n",
            "2023-08-22 23:16:13.492783: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_85611\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 232.00it/s]\n",
            "2023-08-22 23:16:13.588077: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_85735\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 1025.00it/s]\n",
            "2023-08-22 23:16:13.677381: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_85859\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 202.36it/s]\n",
            "2023-08-22 23:16:13.784125: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_85983\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 1102.89it/s]\n",
            "2023-08-22 23:16:13.871568: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_86107\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 661.46it/s]\n",
            "2023-08-22 23:16:13.971336: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_86231\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 1017.05it/s]\n",
            "2023-08-22 23:16:14.068854: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_86355\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 598.59it/s]\n",
            "2023-08-22 23:16:14.167911: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_86479\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 336.65it/s]\n",
            "2023-08-22 23:16:14.261858: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_86603\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 300.75it/s]\n",
            "2023-08-22 23:16:14.350552: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_86727\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 353.77it/s]\n",
            "2023-08-22 23:16:14.453379: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_86851\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 331.02it/s]\n",
            "2023-08-22 23:16:14.554171: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_86975\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 411.49it/s]\n",
            "2023-08-22 23:16:14.640592: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_87099\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 253.60it/s]\n",
            "2023-08-22 23:16:14.743155: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_87223\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 523.63it/s]\n",
            "2023-08-22 23:16:14.836232: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_87347\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 535.47it/s]\n",
            "2023-08-22 23:16:14.953277: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_87471\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 534.58it/s]\n",
            "2023-08-22 23:16:15.054405: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_87595\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 384.80it/s]\n",
            "2023-08-22 23:16:15.169614: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_87719\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 256.06it/s]\n",
            "2023-08-22 23:16:15.265059: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_87843\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 221.44it/s]\n",
            "2023-08-22 23:16:15.377583: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_87967\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 455.11it/s]\n",
            "2023-08-22 23:16:15.482961: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_88091\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 355.00it/s]\n",
            "2023-08-22 23:16:15.594071: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_88215\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 1056.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-08-22 23:16:15.690582: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"PrefetchDataset/_8\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_slice_batch_indices_88339\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
          ]
        }
      ],
      "source": [
        "test_df['predict'] = test_df['sentences'].apply(\n",
        "    lambda x: ner_prediction([x], max_seq_len=128, tokenizer=tokenizer)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7V1F0K8m3v2",
        "outputId": "ca2aa8d2-a6bb-483a-a420-23fab755d1c0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentences</th>\n",
              "      <th>morpheme</th>\n",
              "      <th>bio_tag</th>\n",
              "      <th>pos</th>\n",
              "      <th>format</th>\n",
              "      <th>predict</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>성대결절은 발성의 문제가 있을 때 생기게 됩니다 .</td>\n",
              "      <td>XXXXO OOO OOO OO O OOO OOO O</td>\n",
              "      <td>B-DS O O O O O O O</td>\n",
              "      <td>(성대,NNG) / (결절,NNG) / (은,JX) / (발성,NNG) / (의,J...</td>\n",
              "      <td>Word | POS | Entity | BIO | Thought \\n성대결절은 |성...</td>\n",
              "      <td>O O O O O O O O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>현재 허리 통증이 심한 상태라면 , 보다 정밀한 진찰을 받아 야 합니다 .</td>\n",
              "      <td>OO XX XXO OO OOOO O OO OOO OOO OO O OOO O</td>\n",
              "      <td>O B-BD B-ST O O O O O O O O O O</td>\n",
              "      <td>(현재,MAG) / (허리,NNG) / (통증,NNG) / (이,JKS) / (심한...</td>\n",
              "      <td>Word | POS | Entity | BIO | Thought \\n현재 |현재(M...</td>\n",
              "      <td>O O O O O O O O O O O O O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>시간이 가면서 이런 신호가 나온다면 감기 오고 있다는 증거가 될 수 있읍니다 .</td>\n",
              "      <td>OOO OOO OO OOO OOOO XX OO OOO OOO O O OOOO O</td>\n",
              "      <td>O O O O O B-ST O O O O O O O</td>\n",
              "      <td>(시간,NNG) / (이,JKS) / (가,VV) / (면서,EC) / (이런,MM...</td>\n",
              "      <td>Word | POS | Entity | BIO | Thought \\n시간이 |시간(...</td>\n",
              "      <td>O O O O O O O O O O O O O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>기관지 천식인지 , 기관지 과민성인지 , 기타 다른 호흡기 질환이나 심장 질환이 동...</td>\n",
              "      <td>XXX XXOO O XXX XXXOO O OO OO XXX OOOO XX OOO O...</td>\n",
              "      <td>B-DS I-DS O B-DS I-DS O O O B-BD O B-BD O O O ...</td>\n",
              "      <td>(기관지,NNG) / (천식,NNG) / (인지,VCP+EC) / (,,SC) / ...</td>\n",
              "      <td>Word | POS | Entity | BIO | Thought \\n기관지 |기관지...</td>\n",
              "      <td>O O O O O O O O O O O O O O O O O O O O O O O O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>갑상선 기능 저하증이 조절되지 않으면 간 기능 검사상 수치가 상승되는 경우가 많고 ...</td>\n",
              "      <td>XXX XX XXXO OOOO OOO O OO OOO OOO OOOO OOO OO ...</td>\n",
              "      <td>B-DS I-DS I-DS O O O O O O O O O O B-DS O O O ...</td>\n",
              "      <td>(갑상선,NNG) / (기능,NNG) / (저하,NNG) / (증이,NNG) / (...</td>\n",
              "      <td>Word | POS | Entity | BIO | Thought \\n갑상선 |갑상선...</td>\n",
              "      <td>O O O O O O O O O O O O O O O O O O O O O O O O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           sentences  \\\n",
              "0                       성대결절은 발성의 문제가 있을 때 생기게 됩니다 .   \n",
              "1          현재 허리 통증이 심한 상태라면 , 보다 정밀한 진찰을 받아 야 합니다 .   \n",
              "2       시간이 가면서 이런 신호가 나온다면 감기 오고 있다는 증거가 될 수 있읍니다 .   \n",
              "3  기관지 천식인지 , 기관지 과민성인지 , 기타 다른 호흡기 질환이나 심장 질환이 동...   \n",
              "4  갑상선 기능 저하증이 조절되지 않으면 간 기능 검사상 수치가 상승되는 경우가 많고 ...   \n",
              "\n",
              "                                            morpheme  \\\n",
              "0                       XXXXO OOO OOO OO O OOO OOO O   \n",
              "1          OO XX XXO OO OOOO O OO OOO OOO OO O OOO O   \n",
              "2       OOO OOO OO OOO OOOO XX OO OOO OOO O O OOOO O   \n",
              "3  XXX XXOO O XXX XXXOO O OO OO XXX OOOO XX OOO O...   \n",
              "4  XXX XX XXXO OOOO OOO O OO OOO OOO OOOO OOO OO ...   \n",
              "\n",
              "                                             bio_tag  \\\n",
              "0                                 B-DS O O O O O O O   \n",
              "1                    O B-BD B-ST O O O O O O O O O O   \n",
              "2                       O O O O O B-ST O O O O O O O   \n",
              "3  B-DS I-DS O B-DS I-DS O O O B-BD O B-BD O O O ...   \n",
              "4  B-DS I-DS I-DS O O O O O O O O O O B-DS O O O ...   \n",
              "\n",
              "                                                 pos  \\\n",
              "0  (성대,NNG) / (결절,NNG) / (은,JX) / (발성,NNG) / (의,J...   \n",
              "1  (현재,MAG) / (허리,NNG) / (통증,NNG) / (이,JKS) / (심한...   \n",
              "2  (시간,NNG) / (이,JKS) / (가,VV) / (면서,EC) / (이런,MM...   \n",
              "3  (기관지,NNG) / (천식,NNG) / (인지,VCP+EC) / (,,SC) / ...   \n",
              "4  (갑상선,NNG) / (기능,NNG) / (저하,NNG) / (증이,NNG) / (...   \n",
              "\n",
              "                                              format  \\\n",
              "0  Word | POS | Entity | BIO | Thought \\n성대결절은 |성...   \n",
              "1  Word | POS | Entity | BIO | Thought \\n현재 |현재(M...   \n",
              "2  Word | POS | Entity | BIO | Thought \\n시간이 |시간(...   \n",
              "3  Word | POS | Entity | BIO | Thought \\n기관지 |기관지...   \n",
              "4  Word | POS | Entity | BIO | Thought \\n갑상선 |갑상선...   \n",
              "\n",
              "                                           predict  \n",
              "0                                  O O O O O O O O  \n",
              "1                        O O O O O O O O O O O O O  \n",
              "2                        O O O O O O O O O O O O O  \n",
              "3  O O O O O O O O O O O O O O O O O O O O O O O O  \n",
              "4  O O O O O O O O O O O O O O O O O O O O O O O O  "
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_df.to_csv(\"./train_result/all_train/bert-base-uncased/result_1.csv\",encoding='cp949')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [],
      "name": "kor_bert_ner_model_from_transformers_tpu.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.16 ('sy')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "vscode": {
      "interpreter": {
        "hash": "c8912a2ac60011df5c7929c5b17fec914cfb6aaebbe86976a2caeafe12776e03"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "05e9e8f85db540ff85f52aea19b9b2b4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "061869c46a1c48108f4491dac486f4a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3db8cefdbe934c9a94f169b67841474c",
              "IPY_MODEL_2830ac03d9e94371867426361e071deb",
              "IPY_MODEL_0a1834c29de34a738729166b32b3a49c"
            ],
            "layout": "IPY_MODEL_297c73cff2b44fbd879ee6a88248e0bb"
          }
        },
        "094ac3c76547450a9920221509b0fc2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_150906ccddba473099c62156945f0f84",
            "placeholder": "​",
            "style": "IPY_MODEL_f3857681b6b342e68c9f46e4fd087db3",
            "value": " 289/289 [00:00&lt;00:00, 7.22kB/s]"
          }
        },
        "0a1834c29de34a738729166b32b3a49c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a403653781d4d24b2aaeb7f0ce8e783",
            "placeholder": "​",
            "style": "IPY_MODEL_44d21b5cbf5446808dad177bbaeb154a",
            "value": " 125/125 [00:00&lt;00:00, 3.38kB/s]"
          }
        },
        "150906ccddba473099c62156945f0f84": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16029875a7794882934f144f2c5e83d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1881c272a0e745c4bb2d83f49c2bf2ed": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fedcaac82d14bd29a78b30839cb9d3f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2830ac03d9e94371867426361e071deb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d3ff09d980f42c18622421ef7e1b28d",
            "max": 125,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c367d6638f874ef99e839542e41f92e2",
            "value": 125
          }
        },
        "297c73cff2b44fbd879ee6a88248e0bb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a6b8bc7fa7140d4a6b50b3754fe0041": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_574e313faa2049a38236b0eb33a75b8c",
            "max": 425,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d514948d07554566925f8d36ac3ffbd4",
            "value": 425
          }
        },
        "2b86553056d641de8451e14acbf18e8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_687cb1161a6c4ac395837b89fb65fdee",
            "max": 289,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_905f7c6c486e4c5d94a55e74f16ebf2f",
            "value": 289
          }
        },
        "2d920f8649e14db081002a171528f5d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "34f100f51efe4e30bb70a53db59e2d80": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35442ebd192d4d779feb15c98ad168bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1881c272a0e745c4bb2d83f49c2bf2ed",
            "placeholder": "​",
            "style": "IPY_MODEL_60cfc3a79a854a64a1daac329af94011",
            "value": " 243k/243k [00:00&lt;00:00, 1.45MB/s]"
          }
        },
        "3a403653781d4d24b2aaeb7f0ce8e783": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3db8cefdbe934c9a94f169b67841474c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05e9e8f85db540ff85f52aea19b9b2b4",
            "placeholder": "​",
            "style": "IPY_MODEL_16029875a7794882934f144f2c5e83d8",
            "value": "Downloading: 100%"
          }
        },
        "4072b7b90b2f4ff3a2ae38b0592a0e08": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "40caa10bf7bd458cbf881aacde892c7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d4cf6a2aecb44be8abd2a4bebae215f",
            "max": 248477,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6d18b1dd6f364f3d9aead1c5e2c9e865",
            "value": 248477
          }
        },
        "44d21b5cbf5446808dad177bbaeb154a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "479d63d134b5483baca4c1e788841c82": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_af3708e166ad41a5b5a319d42a43d6f4",
              "IPY_MODEL_2b86553056d641de8451e14acbf18e8d",
              "IPY_MODEL_094ac3c76547450a9920221509b0fc2c"
            ],
            "layout": "IPY_MODEL_34f100f51efe4e30bb70a53db59e2d80"
          }
        },
        "487dc744300a4a1298f75743774f6345": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e50ec514f4cb4b7bb76ff8970a95bf02",
            "placeholder": "​",
            "style": "IPY_MODEL_4072b7b90b2f4ff3a2ae38b0592a0e08",
            "value": "Downloading: 100%"
          }
        },
        "51cc4aca4edb488a9817a0796e6e4f77": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "574e313faa2049a38236b0eb33a75b8c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60cfc3a79a854a64a1daac329af94011": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6818e90fd30242d495541a6cfd409b39": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0952ae8def047f6b91c255b21f7d641",
            "placeholder": "​",
            "style": "IPY_MODEL_a9019760876948cdaa041cf9992bf836",
            "value": " 483k/483k [00:00&lt;00:00, 1.31MB/s]"
          }
        },
        "687cb1161a6c4ac395837b89fb65fdee": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6898886cbbd2409ebda14ed60b2ab66a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ea660b90857b4a868856fa0007301d37",
              "IPY_MODEL_2a6b8bc7fa7140d4a6b50b3754fe0041",
              "IPY_MODEL_fb942159ac5b4d4c860fa2d1dc52cbb7"
            ],
            "layout": "IPY_MODEL_fdf338e909014103bc05075e4475d7b6"
          }
        },
        "6cbe1c616d714cf1b1c3efa2de2a7f32": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6d18b1dd6f364f3d9aead1c5e2c9e865": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6d3ff09d980f42c18622421ef7e1b28d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d4cf6a2aecb44be8abd2a4bebae215f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81b2acbbb3a74a4da72bf683356c9516": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82f523cf687e47a09b60b40799b89ebc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a58ad45da34c465abc195c48a4540f84",
            "max": 494860,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f8bbf740987640819dcd1581ac636c50",
            "value": 494860
          }
        },
        "83d77ecbada443b8acbef2aa58dfa9a2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87b7a6fbc7604ead99c659ce5aed4fae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cb77c882ad5a46ce96ef556c41132710",
              "IPY_MODEL_40caa10bf7bd458cbf881aacde892c7f",
              "IPY_MODEL_35442ebd192d4d779feb15c98ad168bc"
            ],
            "layout": "IPY_MODEL_c760d63796f248f6892f05c141be9717"
          }
        },
        "8fb1d9ee86984f1fb4d55df84855000f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_487dc744300a4a1298f75743774f6345",
              "IPY_MODEL_82f523cf687e47a09b60b40799b89ebc",
              "IPY_MODEL_6818e90fd30242d495541a6cfd409b39"
            ],
            "layout": "IPY_MODEL_83d77ecbada443b8acbef2aa58dfa9a2"
          }
        },
        "905f7c6c486e4c5d94a55e74f16ebf2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9d76271c920c4fac8934091ee4215dde": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9fb14288f90f4f729ece674c4f37a736": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a0952ae8def047f6b91c255b21f7d641": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a58ad45da34c465abc195c48a4540f84": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9019760876948cdaa041cf9992bf836": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "af3708e166ad41a5b5a319d42a43d6f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81b2acbbb3a74a4da72bf683356c9516",
            "placeholder": "​",
            "style": "IPY_MODEL_2d920f8649e14db081002a171528f5d8",
            "value": "Downloading: 100%"
          }
        },
        "c259d5b958bd4e19a5aa225d9bb1f057": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c367d6638f874ef99e839542e41f92e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c760d63796f248f6892f05c141be9717": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb77c882ad5a46ce96ef556c41132710": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51cc4aca4edb488a9817a0796e6e4f77",
            "placeholder": "​",
            "style": "IPY_MODEL_6cbe1c616d714cf1b1c3efa2de2a7f32",
            "value": "Downloading: 100%"
          }
        },
        "d514948d07554566925f8d36ac3ffbd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e50ec514f4cb4b7bb76ff8970a95bf02": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea660b90857b4a868856fa0007301d37": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c259d5b958bd4e19a5aa225d9bb1f057",
            "placeholder": "​",
            "style": "IPY_MODEL_9fb14288f90f4f729ece674c4f37a736",
            "value": "Downloading: 100%"
          }
        },
        "f3857681b6b342e68c9f46e4fd087db3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f8bbf740987640819dcd1581ac636c50": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fb942159ac5b4d4c860fa2d1dc52cbb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1fedcaac82d14bd29a78b30839cb9d3f",
            "placeholder": "​",
            "style": "IPY_MODEL_9d76271c920c4fac8934091ee4215dde",
            "value": " 425/425 [00:00&lt;00:00, 7.21kB/s]"
          }
        },
        "fdf338e909014103bc05075e4475d7b6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
